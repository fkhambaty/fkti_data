<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Logistic Regression - Complete Guide | Fakhruddin Khambaty's Learning Hub</title>
    <link href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;500;600;700;800&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body {
            font-family: 'Nunito', sans-serif;
            background: linear-gradient(135deg, #e0f2fe 0%, #bae6fd 50%, #7dd3fc 100%);
            min-height: 100vh;
            padding: 20px;
            color: #1e293b;
            line-height: 2;
            font-size: 18px;
        }
        
        .container { max-width: 900px; margin: 0 auto; }
        
        .nav {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            padding: 15px 30px;
            border-radius: 15px;
            margin-bottom: 30px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.08);
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .nav a { color: #0284c7; text-decoration: none; font-weight: 600; display: flex; align-items: center; gap: 8px; }
        .nav a:hover { color: #0369a1; }
        
        .header {
            text-align: center;
            padding: 50px 40px;
            background: linear-gradient(135deg, #0ea5e9 0%, #0284c7 50%, #0369a1 100%);
            border-radius: 25px;
            color: white;
            margin-bottom: 40px;
            box-shadow: 0 10px 40px rgba(14, 165, 233, 0.3);
        }
        
        .header h1 { font-size: 2.5em; margin-bottom: 15px; font-weight: 800; }
        .header p { font-size: 1.2em; opacity: 0.95; max-width: 700px; margin: 0 auto; }
        
        .beginner-badge {
            background: #f59e0b;
            color: white;
            padding: 8px 20px;
            border-radius: 25px;
            font-weight: 700;
            display: inline-block;
            margin-bottom: 20px;
            font-size: 0.9em;
        }
        
        .section {
            background: white;
            border-radius: 25px;
            padding: 45px;
            margin-bottom: 35px;
            box-shadow: 0 4px 25px rgba(0,0,0,0.08);
            border: 3px solid #bae6fd;
        }
        
        .section h2 { color: #0284c7; font-size: 1.8em; margin-bottom: 25px; display: flex; align-items: center; gap: 15px; padding-bottom: 15px; border-bottom: 3px solid #e0f2fe; }
        .section h3 { color: #0369a1; font-size: 1.4em; margin: 35px 0 20px 0; padding-left: 20px; border-left: 5px solid #0ea5e9; }
        .section p { font-size: 1.1em; color: #334155; margin-bottom: 20px; }
        
        .eli5-box {
            background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%);
            border-radius: 20px;
            padding: 30px;
            margin: 25px 0;
            border: 3px dashed #f59e0b;
        }
        .eli5-box h4 { color: #92400e; font-size: 1.3em; margin-bottom: 15px; }
        .eli5-box p { color: #78350f; font-size: 1.15em; margin-bottom: 10px; }
        
        .visual-example {
            background: linear-gradient(135deg, #ecfdf5 0%, #d1fae5 100%);
            border-radius: 20px;
            padding: 30px;
            margin: 25px 0;
            border: 3px solid #10b981;
            text-align: center;
        }
        .visual-example h4 { color: #047857; font-size: 1.2em; margin-bottom: 20px; }
        
        .code-block {
            background: #1e293b;
            border-radius: 20px;
            padding: 30px;
            margin: 25px 0;
            overflow-x: auto;
        }
        .code-block pre { margin: 0; font-family: 'Fira Code', monospace; font-size: 0.95em; color: #e2e8f0; line-height: 1.8; }
        .code-block .comment { color: #94a3b8; }
        .code-block .keyword { color: #c084fc; }
        .code-block .function { color: #38bdf8; }
        .code-block .string { color: #4ade80; }
        .code-block .number { color: #fb923c; }
        .code-block .output { color: #a78bfa; }
        
        .data-table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            background: white;
            border-radius: 15px;
            overflow: hidden;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }
        .data-table th { background: linear-gradient(135deg, #0ea5e9 0%, #0284c7 100%); color: white; padding: 18px 15px; text-align: left; }
        .data-table td { padding: 15px; border-bottom: 2px solid #f1f5f9; }
        .data-table tr:nth-child(even) { background: #e0f2fe; }
        
        .comparison-visual {
            background: linear-gradient(135deg, #f3e8ff 0%, #e9d5ff 100%);
            border-radius: 20px;
            padding: 30px;
            margin: 25px 0;
            border: 3px solid #a855f7;
            font-family: 'Fira Code', monospace;
        }
        .comparison-visual h4 { color: #7c3aed; margin-bottom: 20px; font-family: 'Nunito', sans-serif; }
        .comparison-visual pre { color: #581c87; font-size: 0.9em; line-height: 1.6; }
        
        .warning-box {
            background: linear-gradient(135deg, #fef2f2 0%, #fecaca 100%);
            border-radius: 20px;
            padding: 25px;
            margin: 25px 0;
            border: 3px solid #ef4444;
        }
        .warning-box h4 { color: #b91c1c; margin-bottom: 10px; }
        .warning-box p { color: #991b1b; }
        
        .success-box {
            background: linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%);
            border-radius: 20px;
            padding: 25px;
            margin: 25px 0;
            border: 3px solid #22c55e;
        }
        .success-box h4 { color: #166534; margin-bottom: 10px; }
        .success-box p { color: #14532d; }
        
        .metric-card {
            background: white;
            border-radius: 15px;
            padding: 20px;
            margin: 15px 0;
            border: 2px solid #e2e8f0;
        }
        .metric-card h5 { color: #0284c7; margin-bottom: 10px; font-size: 1.1em; }
        
        .nav-buttons { display: flex; justify-content: space-between; margin-top: 50px; gap: 20px; flex-wrap: wrap; }
        .nav-btn { display: inline-flex; align-items: center; gap: 10px; padding: 18px 35px; border-radius: 15px; text-decoration: none; font-weight: 700; transition: all 0.3s; }
        .nav-btn.prev { background: #f1f5f9; color: #475569; }
        .nav-btn.next { background: linear-gradient(135deg, #0ea5e9 0%, #0284c7 100%); color: white; }
        .nav-btn:hover { transform: translateY(-3px); box-shadow: 0 8px 25px rgba(0,0,0,0.15); }
        
        .back-to-top { position: fixed; bottom: 30px; right: 30px; width: 55px; height: 55px; background: linear-gradient(135deg, #0ea5e9 0%, #0284c7 100%); color: white; border: none; border-radius: 50%; cursor: pointer; display: flex; align-items: center; justify-content: center; font-size: 22px; z-index: 1000; opacity: 0; visibility: hidden; transition: all 0.3s; }
        .back-to-top.show { opacity: 1; visibility: visible; }
        
        @media (max-width: 768px) {
            body { padding: 10px; font-size: 16px; }
            .header { padding: 30px 20px; }
            .header h1 { font-size: 1.8em; }
            .section { padding: 25px 20px; }
            .nav-buttons { flex-direction: column; }
        }
    </style>
</head>
<body>
    <div class="container">
        <nav class="nav">
            <a href="bias-variance.html"><i class="fas fa-arrow-left"></i><span>Previous: Bias & Variance</span></a>
            <a href="index.html"><i class="fas fa-home"></i><span>Course Hub</span></a>
        </nav>

        <div class="header">
            <span class="beginner-badge">ğŸ¥ REAL HEALTHCARE CASE STUDY</span>
            <h1>ğŸ“Š Logistic Regression</h1>
            <p>Predict heart disease risk! Learn classification, probability, confusion matrix, and how to handle imbalanced data.</p>
        </div>

        <!-- CHAPTER 1: WHAT IS LOGISTIC REGRESSION -->
        <div class="section">
            <h2><i class="fas fa-heart-pulse"></i> Chapter 1: What is Logistic Regression?</h2>
            
            <div class="eli5-box">
                <h4>ğŸ‘¶ Linear vs Logistic - What's the Difference?</h4>
                <p><strong>Linear Regression:</strong> Predicts a NUMBER (house price = $350,000)</p>
                <p><strong>Logistic Regression:</strong> Predicts a CATEGORY (Will get heart disease? Yes/No)</p>
                <p>Despite the name "Regression", Logistic Regression is used for <strong>Classification</strong>!</p>
            </div>

            <div class="comparison-visual">
                <h4>ğŸ”¢ Linear vs ğŸ“‹ Logistic</h4>
<pre>
LINEAR REGRESSION (Predict Numbers):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input: House size, bedrooms, location
Output: $425,000 (continuous number)

            Price
              ^
         450K â”‚        â—
         400K â”‚      â—
         350K â”‚    â—
         300K â”‚  â—
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Size


LOGISTIC REGRESSION (Predict Categories):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input: Age, BP, cholesterol, smoking
Output: 0 (No heart disease) or 1 (Yes)

         Probability
              ^
          1.0 â”‚          â—â—â—â—â—â—
              â”‚        â—
          0.5 â”‚      â—    â† S-shaped curve!
              â”‚    â—
          0.0 â”‚â—â—â—â—â—
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Risk Score
</pre>
            </div>

            <div class="eli5-box">
                <h4>ğŸ¤” Why Not Just Use Linear Regression for Yes/No?</h4>
                <p>Linear Regression can output 1.5 or -0.3 (doesn't make sense for Yes/No!)</p>
                <p>Logistic Regression uses a <strong>Sigmoid function</strong> to squeeze outputs between 0 and 1.</p>
                <p>Output > 0.5 â†’ Predict "Yes" (1)</p>
                <p>Output â‰¤ 0.5 â†’ Predict "No" (0)</p>
            </div>
        </div>

        <!-- CHAPTER 2: THE DATASET -->
        <div class="section">
            <h2><i class="fas fa-database"></i> Chapter 2: Understanding Our Dataset</h2>
            
            <p>We're using the <strong>Framingham Heart Study</strong> dataset to predict <strong>10-year risk of Coronary Heart Disease (CHD)</strong>.</p>
            
            <div class="success-box" style="display: flex; align-items: center; gap: 20px; flex-wrap: wrap;">
                <div style="flex: 1;">
                    <h4>ğŸ“¥ Download the Dataset to Follow Along!</h4>
                    <p style="margin-bottom: 0;">Download this CSV file and save it in your working directory to run the code examples.</p>
                </div>
                <a href="datasets/heart_disease_dataset.csv" download="heart_disease_dataset.csv" 
                   style="background: linear-gradient(135deg, #22c55e 0%, #16a34a 100%); 
                          color: white; padding: 15px 30px; border-radius: 12px; 
                          text-decoration: none; font-weight: 700; display: inline-flex; 
                          align-items: center; gap: 10px; box-shadow: 0 4px 15px rgba(34, 197, 94, 0.3);
                          transition: transform 0.2s, box-shadow 0.2s;">
                    <i class="fas fa-download"></i> Download CSV (191 KB)
                </a>
                <p style="margin-top: 12px;"><a href="logistic-regression-code-walkthrough.html" style="color: #166534; font-weight: 700;">ğŸ“– Full code walkthrough (every line explained)</a></p>
            </div>
            
            <table class="data-table">
                <tr>
                    <th>Feature</th>
                    <th>Description</th>
                    <th>Type</th>
                </tr>
                <tr>
                    <td><strong>male</strong></td>
                    <td>Gender (1 = male, 0 = female)</td>
                    <td>Categorical</td>
                </tr>
                <tr>
                    <td><strong>age</strong></td>
                    <td>Age of patient</td>
                    <td>Numerical</td>
                </tr>
                <tr>
                    <td><strong>currentSmoker</strong></td>
                    <td>Is patient a current smoker?</td>
                    <td>Categorical</td>
                </tr>
                <tr>
                    <td><strong>cigsPerDay</strong></td>
                    <td>Cigarettes smoked per day</td>
                    <td>Numerical</td>
                </tr>
                <tr>
                    <td><strong>BPMeds</strong></td>
                    <td>On blood pressure medication?</td>
                    <td>Categorical</td>
                </tr>
                <tr>
                    <td><strong>prevalentStroke</strong></td>
                    <td>Had a stroke before?</td>
                    <td>Categorical</td>
                </tr>
                <tr>
                    <td><strong>prevalentHyp</strong></td>
                    <td>Is patient hypertensive?</td>
                    <td>Categorical</td>
                </tr>
                <tr>
                    <td><strong>diabetes</strong></td>
                    <td>Has diabetes?</td>
                    <td>Categorical</td>
                </tr>
                <tr>
                    <td><strong>totChol</strong></td>
                    <td>Total cholesterol level</td>
                    <td>Numerical</td>
                </tr>
                <tr>
                    <td><strong>sysBP / diaBP</strong></td>
                    <td>Systolic / Diastolic blood pressure</td>
                    <td>Numerical</td>
                </tr>
                <tr>
                    <td><strong>BMI</strong></td>
                    <td>Body Mass Index</td>
                    <td>Numerical</td>
                </tr>
                <tr>
                    <td><strong>glucose</strong></td>
                    <td>Blood glucose level</td>
                    <td>Numerical</td>
                </tr>
                <tr style="background: #fef3c7;">
                    <td><strong>TenYearCHD</strong> ğŸ¯</td>
                    <td>10-year risk of heart disease (TARGET)</td>
                    <td>0 = No, 1 = Yes</td>
                </tr>
            </table>
        </div>

        <!-- CHAPTER 3: STEP BY STEP CODE -->
        <div class="section">
            <h2><i class="fas fa-code"></i> Chapter 3: Building the Model Step-by-Step</h2>
            
            <h3>Step 1: Import Libraries & Load Data</h3>
            
            <div class="code-block">
<pre><span class="keyword">import</span> pandas <span class="keyword">as</span> pd
<span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">import</span> seaborn <span class="keyword">as</span> sns
<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt

<span class="comment"># Machine Learning imports</span>
<span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler
<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split
<span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression
<span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, accuracy_score, classification_report

<span class="comment"># Load the heart disease dataset (download from link above!)</span>
data = pd.<span class="function">read_csv</span>(<span class="string">"heart_disease_dataset.csv"</span>)
<span class="function">print</span>(<span class="string">f"Dataset shape: {data.shape}"</span>)
<span class="function">print</span>(data.<span class="function">head</span>())

<span class="output"># Dataset shape: (4238, 16)</span>
<span class="output">#    male  age  education  currentSmoker  cigsPerDay  ...</span></pre>
            </div>
            <div class="eli5-box" style="background: linear-gradient(135deg, #ecfdf5 0%, #d1fae5 100%); border-left: 4px solid #10b981;">
                <h4>What each part does (in simple words)</h4>
                <p><strong>pd.read_csv(...)</strong> â€” Loads the heart disease CSV into <code>data</code>.</p>
                <p><strong>data.shape</strong> â€” Number of rows and columns.</p>
                <p><strong>data.head()</strong> â€” First 5 rows. Other lines: imports for scaling, train/test split, LogisticRegression, and metrics.</p>
                <p style="margin-top: 10px;"><a href="logistic-regression-code-walkthrough.html">Full line-by-line walkthrough â†’</a></p>
            </div>

            <h3>Step 2: Check for Missing Values</h3>
            
            <div class="code-block">
<pre><span class="comment"># Check missing values</span>
<span class="function">print</span>(data.<span class="function">isnull</span>().<span class="function">sum</span>())

<span class="output"># male                 0</span>
<span class="output"># age                  0</span>
<span class="output"># cigsPerDay          29  â† Missing!</span>
<span class="output"># totChol             50  â† Missing!</span>
<span class="output"># BMI                 19  â† Missing!</span>
<span class="output"># heartRate            1  â† Missing!</span>
<span class="output"># glucose            388  â† Missing!</span>
<span class="output"># TenYearCHD           0</span></pre>
            </div>

            <h3>Step 3: Handle Missing Values</h3>
            
            <div class="eli5-box">
                <h4>ğŸ¤” Why Median Instead of Mean?</h4>
                <p><strong>Mean</strong> is affected by outliers (extreme values pull it up/down)</p>
                <p><strong>Median</strong> is robust - it's the middle value, unaffected by outliers!</p>
                <p>For medical data with potential extreme values, median is safer.</p>
            </div>

            <div class="code-block">
<pre><span class="comment"># Fill missing values with MEDIAN (robust to outliers)</span>
numerical_columns = [<span class="string">'cigsPerDay'</span>, <span class="string">'totChol'</span>, <span class="string">'BMI'</span>, <span class="string">'heartRate'</span>, <span class="string">'glucose'</span>]

<span class="keyword">for</span> col <span class="keyword">in</span> numerical_columns:
    median_value = data[col].<span class="function">median</span>()
    data[col] = data[col].<span class="function">fillna</span>(median_value)
    <span class="function">print</span>(<span class="string">f"{col}: filled with median = {median_value}"</span>)

<span class="comment"># Verify no more missing values</span>
<span class="function">print</span>(<span class="string">"\nMissing values after imputation:"</span>)
<span class="function">print</span>(data.<span class="function">isnull</span>().<span class="function">sum</span>().<span class="function">sum</span>())  <span class="output"># Output: 0</span></pre>
            </div>

            <h3>Step 4: Visualize Numerical Features</h3>
            
            <div class="code-block">
<pre><span class="comment"># Boxplots: Compare features between heart disease (1) vs no heart disease (0)</span>
plt.<span class="function">figure</span>(figsize=(<span class="number">20</span>, <span class="number">12</span>))

features_to_plot = [<span class="string">'age'</span>, <span class="string">'totChol'</span>, <span class="string">'sysBP'</span>, <span class="string">'diaBP'</span>, <span class="string">'BMI'</span>, 
                    <span class="string">'heartRate'</span>, <span class="string">'glucose'</span>, <span class="string">'cigsPerDay'</span>]

<span class="keyword">for</span> i, col <span class="keyword">in</span> <span class="function">enumerate</span>(features_to_plot, <span class="number">1</span>):
    plt.<span class="function">subplot</span>(<span class="number">3</span>, <span class="number">3</span>, i)
    sns.<span class="function">boxplot</span>(x=<span class="string">'TenYearCHD'</span>, y=col, data=data, hue=<span class="string">'TenYearCHD'</span>, palette=<span class="string">'Set2'</span>, legend=<span class="keyword">False</span>)
    plt.<span class="function">title</span>(<span class="string">f'{col} by Heart Disease Risk'</span>)

plt.<span class="function">tight_layout</span>()
plt.<span class="function">show</span>()</pre>
            </div>

            <div class="visual-example">
                <h4>ğŸ“Š What the Boxplots Tell Us</h4>
                <ul style="text-align: left; margin-left: 30px;">
                    <li><strong>Age:</strong> Heart disease patients are generally OLDER</li>
                    <li><strong>sysBP (Systolic BP):</strong> Higher in heart disease group</li>
                    <li><strong>Glucose:</strong> Higher in heart disease group</li>
                    <li><strong>Cholesterol:</strong> Slightly higher in heart disease group</li>
                </ul>
            </div>

            <h3>Step 5: Check Correlation</h3>
            
            <div class="code-block">
<pre><span class="comment"># Correlation heatmap for numerical features</span>
numerical_cols = [<span class="string">'age'</span>, <span class="string">'cigsPerDay'</span>, <span class="string">'totChol'</span>, <span class="string">'BMI'</span>, <span class="string">'heartRate'</span>, 
                  <span class="string">'glucose'</span>, <span class="string">'sysBP'</span>, <span class="string">'diaBP'</span>]

plt.<span class="function">figure</span>(figsize=(<span class="number">10</span>, <span class="number">8</span>))
sns.<span class="function">heatmap</span>(data[numerical_cols].<span class="function">corr</span>(), cmap=<span class="string">"YlGnBu"</span>, annot=<span class="keyword">True</span>, fmt=<span class="string">".2f"</span>)
plt.<span class="function">title</span>(<span class="string">"Correlation Between Numerical Features"</span>)
plt.<span class="function">show</span>()</pre>
            </div>

            <div class="eli5-box">
                <h4>ğŸ” Key Finding: sysBP & diaBP are Highly Correlated (0.79)</h4>
                <p><strong>sysBP</strong> (Systolic): Pressure when heart beats</p>
                <p><strong>diaBP</strong> (Diastolic): Pressure when heart relaxes</p>
                <p>They measure similar things, so they're correlated. In advanced models, you might drop one!</p>
            </div>

            <h3>Step 6: Split Data & Scale Features</h3>
            
            <div class="code-block">
<pre><span class="comment"># Separate features (X) and target (y)</span>
y = data[<span class="string">"TenYearCHD"</span>]              <span class="comment"># What we want to predict</span>
X = data.<span class="function">drop</span>(<span class="string">'TenYearCHD'</span>, axis=<span class="number">1</span>)  <span class="comment"># Everything else</span>

<span class="comment"># Train-test split (80% train, 20% test)</span>
X_train, X_test, y_train, y_test = <span class="function">train_test_split</span>(
    X, y, test_size=<span class="number">0.20</span>, random_state=<span class="number">0</span>
)

<span class="comment"># Scale features to 0-1 range (important for Logistic Regression!)</span>
scaler = <span class="function">MinMaxScaler</span>()
X_train = scaler.<span class="function">fit_transform</span>(X_train)  <span class="comment"># Fit AND transform on training</span>
X_test = scaler.<span class="function">transform</span>(X_test)         <span class="comment"># Only transform on test</span>

<span class="function">print</span>(<span class="string">f"Training samples: {len(X_train)}"</span>)
<span class="function">print</span>(<span class="string">f"Test samples: {len(X_test)}"</span>)
<span class="output"># Training samples: 3390</span>
<span class="output"># Test samples: 848</span></pre>
            </div>
        </div>

        <!-- CHAPTER 4: TRAINING & EVALUATION -->
        <div class="section">
            <h2><i class="fas fa-brain"></i> Chapter 4: Train & Evaluate the Model</h2>
            
            <h3>Step 7: Train the Model</h3>
            
            <div class="code-block">
<pre><span class="comment"># Create and train Logistic Regression model</span>
model = <span class="function">LogisticRegression</span>()
model.<span class="function">fit</span>(X_train, y_train)

<span class="comment"># Make predictions</span>
y_pred = model.<span class="function">predict</span>(X_test)

<span class="comment"># Check accuracy</span>
accuracy = <span class="function">accuracy_score</span>(y_test, y_pred)
<span class="function">print</span>(<span class="string">f"Accuracy: {accuracy:.2%}"</span>)
<span class="output"># Accuracy: 84.55%</span></pre>
            </div>

            <div class="warning-box">
                <h4>âš ï¸ Wait! 84.55% Accuracy Sounds Great... But Is It?</h4>
                <p>Let's look deeper at what the model is actually doing!</p>
            </div>

            <h3>Step 8: The Confusion Matrix</h3>
            
            <div class="eli5-box">
                <h4>ğŸ¤· What is a Confusion Matrix?</h4>
                <p>It shows WHERE your model makes mistakes:</p>
                <ul style="margin-left: 20px;">
                    <li><strong>True Negative (TN):</strong> Predicted NO, Actually NO âœ…</li>
                    <li><strong>True Positive (TP):</strong> Predicted YES, Actually YES âœ…</li>
                    <li><strong>False Positive (FP):</strong> Predicted YES, Actually NO âŒ (False Alarm)</li>
                    <li><strong>False Negative (FN):</strong> Predicted NO, Actually YES âŒ (MISSED!)</li>
                </ul>
            </div>

            <div class="code-block">
<pre><span class="comment"># Generate confusion matrix</span>
cm = <span class="function">confusion_matrix</span>(y_test, y_pred)
<span class="function">print</span>(<span class="string">"Confusion Matrix:"</span>)
<span class="function">print</span>(cm)

<span class="output">#              Predicted</span>
<span class="output">#              NO    YES</span>
<span class="output"># Actual NO   [[710     0]</span>
<span class="output"># Actual YES   [131     7]]</span></pre>
            </div>

            <div class="comparison-visual">
                <h4>ğŸ“Š What the Confusion Matrix Reveals</h4>
<pre>
                    PREDICTED
                   NO      YES
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
    Actual NO â”‚  710   â”‚    0   â”‚  â† Great! No false alarms
              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   Actual YES â”‚  131   â”‚    7   â”‚  â† PROBLEM! Only caught 7 out of 138!
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Out of 138 people who WILL get heart disease:
    - Model correctly identified: 7 (5%)  ğŸ˜¢
    - Model MISSED: 131 (95%)  ğŸ˜±
    
    âš ï¸ This is TERRIBLE for healthcare!
    Missing heart disease patients is DANGEROUS!
</pre>
            </div>

            <div class="code-block">
<pre><span class="comment"># Full classification report</span>
<span class="function">print</span>(<span class="function">classification_report</span>(y_test, y_pred))

<span class="output">#               precision    recall  f1-score   support</span>
<span class="output">#</span>
<span class="output">#            0       0.84      1.00      0.92       710</span>
<span class="output">#            1       1.00      0.05      0.10       138  â† Recall is only 5%!</span>
<span class="output">#</span>
<span class="output">#     accuracy                           0.85       848</span></pre>
            </div>

            <h3>Understanding the Metrics</h3>
            
            <table class="data-table">
                <tr>
                    <th>Metric</th>
                    <th>Formula</th>
                    <th>Our Value</th>
                    <th>Meaning</th>
                </tr>
                <tr>
                    <td><strong>Accuracy</strong></td>
                    <td>(TP+TN) / Total</td>
                    <td>84.5%</td>
                    <td>Overall correct predictions (MISLEADING here!)</td>
                </tr>
                <tr>
                    <td><strong>Precision</strong></td>
                    <td>TP / (TP+FP)</td>
                    <td>100%</td>
                    <td>When we predict YES, how often correct?</td>
                </tr>
                <tr style="background: #fef2f2;">
                    <td><strong>Recall</strong> ğŸš¨</td>
                    <td>TP / (TP+FN)</td>
                    <td>5%</td>
                    <td>Of actual YES cases, how many did we catch?</td>
                </tr>
                <tr>
                    <td><strong>F1-Score</strong></td>
                    <td>2*(P*R)/(P+R)</td>
                    <td>10%</td>
                    <td>Balance between Precision and Recall</td>
                </tr>
            </table>

            <div class="eli5-box">
                <h4>ğŸ¥ In Healthcare: Recall is CRITICAL!</h4>
                <p>We'd rather have some false alarms (tell healthy people to get checked) than <strong>MISS</strong> someone who actually has heart disease!</p>
                <p>Missing 95% of heart disease patients is unacceptable!</p>
            </div>
        </div>

        <!-- CHAPTER 5: THE IMBALANCED DATA PROBLEM -->
        <div class="section">
            <h2><i class="fas fa-balance-scale"></i> Chapter 5: The Imbalanced Data Problem</h2>
            
            <div class="code-block">
<pre><span class="comment"># Check class distribution</span>
<span class="keyword">from</span> collections <span class="keyword">import</span> Counter

<span class="function">print</span>(<span class="string">"Training set distribution:"</span>)
<span class="function">print</span>(<span class="function">Counter</span>(y_train))
<span class="output"># Counter({0: 2875, 1: 515})</span>

<span class="function">print</span>(<span class="string">"\nPercentages:"</span>)
<span class="function">print</span>(<span class="string">f"No heart disease (0): {2875/3390:.1%}"</span>)
<span class="function">print</span>(<span class="string">f"Heart disease (1): {515/3390:.1%}"</span>)
<span class="output"># No heart disease (0): 84.8%</span>
<span class="output"># Heart disease (1): 15.2%</span></pre>
            </div>

            <div class="eli5-box">
                <h4>ğŸ¤” Why is Imbalanced Data a Problem?</h4>
                <p>The model learns: "If I just predict NO for everyone, I'll be right 85% of the time!"</p>
                <p>It's taking the lazy path instead of learning the actual patterns!</p>
            </div>

            <h3>Solution: Class Weights</h3>
            
            <div class="eli5-box">
                <h4>âš–ï¸ What are Class Weights?</h4>
                <p>We tell the model: "Mistakes on the MINORITY class (heart disease) are MORE EXPENSIVE!"</p>
                <p><strong>Weight {0:1, 1:4}</strong> means missing a heart disease case costs 4x more than a false alarm.</p>
            </div>

            <div class="code-block">
<pre><span class="comment"># Train with class weights to handle imbalance</span>
weight = {<span class="number">0</span>: <span class="number">1</span>, <span class="number">1</span>: <span class="number">4</span|}  <span class="comment"># Penalize missing heart disease 4x more</span>

model_balanced = <span class="function">LogisticRegression</span>(class_weight=weight)
model_balanced.<span class="function">fit</span>(X_train, y_train)

y_pred_balanced = model_balanced.<span class="function">predict</span>(X_test)

<span class="function">print</span>(<span class="string">"Confusion Matrix (Balanced):"</span>)
<span class="function">print</span>(<span class="function">confusion_matrix</span>(y_test, y_pred_balanced))

<span class="output">#              Predicted</span>
<span class="output">#              NO    YES</span>
<span class="output"># Actual NO   [[567   143]</span>
<span class="output"># Actual YES   [ 61    77]]</span></pre>
            </div>

            <div class="comparison-visual">
                <h4>ğŸ“Š Before vs After Class Weights</h4>
<pre>
BEFORE (No weights):              AFTER (With weights):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Caught: 7 out of 138 (5%)         Caught: 77 out of 138 (56%) âœ…
Missed: 131 patients ğŸ˜±           Missed: 61 patients (better!)

Trade-off: More false alarms (143 vs 0), but that's OK in healthcare!
</pre>
            </div>

            <div class="code-block">
<pre><span class="function">print</span>(<span class="function">classification_report</span>(y_test, y_pred_balanced))

<span class="output">#               precision    recall  f1-score   support</span>
<span class="output">#</span>
<span class="output">#            0       0.90      0.80      0.85       710</span>
<span class="output">#            1       0.35      0.56      0.43       138  â† Recall improved: 5% â†’ 56%!</span>
<span class="output">#</span>
<span class="output">#     accuracy                           0.76       848</span></pre>
            </div>

            <div class="success-box">
                <h4>âœ… Success! Recall Improved from 5% to 56%!</h4>
                <p>Accuracy dropped from 85% to 76%, but that's a GOOD trade-off in healthcare.</p>
                <p>We're now catching 56% of heart disease patients instead of just 5%!</p>
            </div>
        </div>

        <!-- CHAPTER 6: MODEL INTERPRETATION -->
        <div class="section">
            <h2><i class="fas fa-magnifying-glass"></i> Chapter 6: Model Interpretation - Odds Ratios</h2>
            
            <div class="eli5-box">
                <h4>ğŸ² What is an Odds Ratio?</h4>
                <p>It tells you how much each feature affects the probability of heart disease:</p>
                <ul style="margin-left: 20px;">
                    <li><strong>Odds Ratio > 1:</strong> INCREASES risk (higher is worse)</li>
                    <li><strong>Odds Ratio < 1:</strong> DECREASES risk (protective)</li>
                    <li><strong>Odds Ratio â‰ˆ 1:</strong> No significant effect</li>
                </ul>
            </div>

            <div class="code-block">
<pre><span class="comment"># Calculate odds ratios</span>
features = X.<span class="function">columns</span>.<span class="function">tolist</span>()
odds_ratios = np.<span class="function">exp</span>(model_balanced.coef_)[<span class="number">0</span>]

<span class="function">print</span>(<span class="string">"Feature Importance (Odds Ratios):"</span>)
<span class="function">print</span>(<span class="string">"="</span> * <span class="number">50</span>)
<span class="keyword">for</span> feature, odds <span class="keyword">in</span> <span class="function">zip</span>(features, odds_ratios):
    <span class="function">print</span>(<span class="string">f"{feature:20s}: {odds:.2f}"</span>)

<span class="output"># Feature Importance (Odds Ratios):</span>
<span class="output"># ==================================================</span>
<span class="output"># male                : 1.52  â† Being male increases risk</span>
<span class="output"># age                 : 11.37 â† AGE is HUGE risk factor!</span>
<span class="output"># education           : 1.00  â† No effect</span>
<span class="output"># currentSmoker       : 1.11  â† Slight increase</span>
<span class="output"># cigsPerDay          : 4.23  â† Major risk factor!</span>
<span class="output"># BPMeds              : 1.17  â† Slight increase</span>
<span class="output"># prevalentStroke     : 2.34  â† Previous stroke increases risk</span>
<span class="output"># prevalentHyp        : 1.47  â† Hypertension increases risk</span>
<span class="output"># diabetes            : 1.78  â† Diabetes increases risk</span>
<span class="output"># totChol             : 2.33  â† High cholesterol increases risk</span>
<span class="output"># sysBP               : 5.59  â† HIGH blood pressure = big risk!</span>
<span class="output"># diaBP               : 0.69  â† Slightly protective (after controlling for sysBP)</span>
<span class="output"># BMI                 : 1.48  â† Higher BMI increases risk</span>
<span class="output"># heartRate           : 0.89  â† Slight protective effect</span>
<span class="output"># glucose             : 2.75  â† High glucose increases risk</span></pre>
            </div>

            <div class="visual-example">
                <h4>ğŸ† Top 5 Heart Disease Risk Factors</h4>
                <ol style="text-align: left; margin-left: 30px; font-size: 1.1em;">
                    <li><strong>Age (11.37x)</strong> - Older = much higher risk</li>
                    <li><strong>Systolic BP (5.59x)</strong> - High blood pressure is dangerous</li>
                    <li><strong>Cigarettes/Day (4.23x)</strong> - Smoking kills</li>
                    <li><strong>Glucose (2.75x)</strong> - High blood sugar is risky</li>
                    <li><strong>Previous Stroke (2.34x)</strong> - History matters</li>
                </ol>
            </div>
        </div>

        <!-- CHAPTER 7: SAVE & LOAD MODEL -->
        <div class="section">
            <h2><i class="fas fa-save"></i> Chapter 7: Save & Load Your Model</h2>
            
            <div class="code-block">
<pre><span class="keyword">import</span> joblib

<span class="comment"># Save the model to a file</span>
joblib.<span class="function">dump</span>(model_balanced, <span class="string">'heart_disease_model.pkl'</span>)
<span class="function">print</span>(<span class="string">"âœ… Model saved!"</span>)

<span class="comment"># Load the model later</span>
loaded_model = joblib.<span class="function">load</span>(<span class="string">'heart_disease_model.pkl'</span>)

<span class="comment"># Use loaded model to predict</span>
new_predictions = loaded_model.<span class="function">predict</span>(X_test)
<span class="function">print</span>(<span class="string">"âœ… Model loaded and working!"</span>)

<span class="comment"># Check model parameters</span>
<span class="function">print</span>(<span class="string">"Model intercept:"</span>, loaded_model.intercept_)
<span class="output"># Model intercept: [-3.07863041]</span></pre>
            </div>

            <div class="eli5-box">
                <h4>ğŸ’¾ Why Save Models?</h4>
                <p>Training takes time! Save your trained model so you can:</p>
                <ul style="margin-left: 20px;">
                    <li>Use it later without retraining</li>
                    <li>Deploy it to a website or app</li>
                    <li>Share it with your team</li>
                </ul>
            </div>
        </div>

        <!-- CHAPTER 8: PROBABILITY PREDICTIONS -->
        <div class="section">
            <h2><i class="fas fa-percentage"></i> Chapter 8: Getting Probability Predictions</h2>
            
            <div class="code-block">
<pre><span class="comment"># Get probabilities instead of just 0/1</span>
probabilities = model_balanced.<span class="function">predict_proba</span>(X_test)

<span class="comment"># Create a nice DataFrame to view results</span>
results = pd.<span class="function">DataFrame</span>({
    <span class="string">'Prob_No_HeartDisease'</span>: probabilities[:, <span class="number">0</span>],
    <span class="string">'Prob_HeartDisease'</span>: probabilities[:, <span class="number">1</span>],
    <span class="string">'Predicted'</span>: model_balanced.<span class="function">predict</span>(X_test),
    <span class="string">'Actual'</span>: y_test.<span class="function">values</span>
})

<span class="function">print</span>(results.<span class="function">head</span>(<span class="number">10</span>))

<span class="output">#    Prob_No_HeartDisease  Prob_HeartDisease  Predicted  Actual</span>
<span class="output"># 0              0.73                 0.27          0       0</span>
<span class="output"># 1              0.92                 0.08          0       0</span>
<span class="output"># 2              0.68                 0.32          0       1  â† Missed!</span>
<span class="output"># 3              0.45                 0.55          1       1  â† Correct!</span>
<span class="output"># 4              0.89                 0.11          0       0</span></pre>
            </div>

            <div class="eli5-box">
                <h4>ğŸ¯ Why Probabilities Matter</h4>
                <p>Instead of just "Yes/No", you can say:</p>
                <p>"This patient has a <strong>55% probability</strong> of heart disease in 10 years."</p>
                <p>Doctors can then decide: High-risk patients need immediate intervention!</p>
            </div>

            <div class="important-box" style="background: linear-gradient(135deg, #fef2f2 0%, #fecaca 100%); border-radius: 16px; padding: 24px; margin: 25px 0; border-left: 5px solid #ef4444;">
                <h4 style="color: #b91c1c;">ğŸš« Common Mistakes in Logistic Regression</h4>
                <ul style="margin-left: 20px; color: #7f1d1d;">
                    <li><strong>Relying only on accuracy when classes are imbalanced</strong> â€” A model that always predicts "no" can have high accuracy; use F1, precision, recall, or AUC-ROC.</li>
                    <li><strong>Using 0.5 as the only threshold</strong> â€” For imbalanced or cost-sensitive problems, a different threshold (e.g. 0.3) may be better; tune using the metric that matters.</li>
                    <li><strong>Forgetting to scale features</strong> â€” Like linear regression, scaling helps the optimizer; use the same scaler fit on training data for test.</li>
                </ul>
            </div>

            <div class="important-box" style="background: linear-gradient(135deg, #eff6ff 0%, #dbeafe 100%); border-radius: 16px; padding: 24px; margin: 25px 0; border-left: 5px solid #3b82f6;">
                <h4 style="color: #1e40af;">ğŸ“˜ From the course notebook (Logistic Regression)</h4>
                <p style="color: #1e3a8a; margin-bottom: 10px;">The course source uses <strong>dataset.csv</strong> (heart disease risk; target <code>TenYearCHD</code>). Key code: <code>data = pd.read_csv("dataset.csv")</code>; <code>StandardScaler</code> or <code>MinMaxScaler</code>; <code>train_test_split</code>; <code>LogisticRegression().fit(X_train, y_train)</code>; <code>confusion_matrix</code>, <code>accuracy_score</code>, <code>roc_curve</code>, <code>classification_report</code>. Download <a href="datasets/dataset.csv" download>dataset.csv</a> from the <a href="datasets.html">datasets page</a>. See <strong>Logistic Regression.pdf</strong> in the course source for slides.</p>
            </div>

            
            <div class="section" style="margin-top: 2rem;">
                <h2>Complete code from course notebook: logistic_regression.ipynb</h2>
                <p>Every line of code from the course notebook (verbatim).</p>
                <div class="code-block" style="max-height: 600px; overflow: auto;">
                    <pre style="white-space: pre; font-size: 0.85em;"># --- Code cell 1 ---
from IPython.core.display import HTML

HTML("""
&lt;style&gt;

h1 { color: blue !important; }
h2 { color: green !important; }
&lt;/style&gt;
""")

# --- Code cell 2 ---
import pandas as pd
#import ydata_profiling as yp
# data preprocessing
from sklearn.preprocessing import StandardScaler
# data splitting
from sklearn.model_selection import train_test_split
from collections import Counter
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report
import seaborn as sns
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np

# --- Code cell 3 ---
data = pd.read_csv("dataset.csv")

# --- Code cell 5 ---
# Sex: male or female
# Age: Age of the patient
# Current Smoker: whether or not the patient is a current smoker 
# Cigs Per Day: the number of cigarettes that the person smoked on average in one day
# BP Meds: whether or not the patient was on blood pressure medication 
# Prevalent Stroke: whether or not the patient had previously had a stroke 
# Prevalent Hyp: whether or not the patient was hypertensive 
# Diabetes: whether or not the patient had diabetes
# Tot Chol: total cholesterol level 
# Sys BP: systolic blood pressure 
# Dia BP: diastolic blood pressure 
# BMI: Body Mass Index 
# Heart Rate: heart rate 
# Glucose: glucose level 

#Predict variable (desired target)
# 10 year risk of coronary heart disease CHD (binary: â€œ1â€, means â€œYesâ€, â€œ0â€ means â€œNoâ€)

# --- Code cell 6 ---
data.head(10)

# --- Code cell 8 ---
data.info()

# --- Code cell 9 ---
print(data.isnull().sum())

# --- Code cell 10 ---
for col in data.columns:
    print(col)
    print(data[col].unique())
    print('\n')

# --- Code cell 12 ---
#categorical_columns = ['education','BPMeds']
numerical_columns = ['cigsPerDay', 'totChol', 'BMI','heartRate', 'glucose']


for column in list(numerical_columns):
   data[column].fillna(data[column].median(),inplace = True)

# --- Code cell 13 ---
print(data.isnull().sum())

# --- Code cell 16 ---
data.head(10)

# --- Code cell 17 ---
# What if we had patinet number column?
# Would that be useful as feature
# Drop such columns from data

# --- Code cell 18 ---
data.columns

# --- Code cell 19 ---
#Visualizing numerical variables

plt.figure(figsize=(20, 12))
plt.subplot(3,3,1)
sns.boxplot(x = 'TenYearCHD', y = 'age', data = data)
plt.subplot(3,3,2)
sns.boxplot(x = 'TenYearCHD', y = 'totChol', data = data)
plt.subplot(3,3,3)
sns.boxplot(x = 'TenYearCHD', y = 'sysBP', data = data)
plt.subplot(3,3,4)
sns.boxplot(x = 'TenYearCHD', y = 'diaBP', data = data)
plt.subplot(3,3,5)
sns.boxplot(x = 'TenYearCHD', y = 'BMI', data = data)
plt.subplot(3,3,6)
sns.boxplot(x = 'TenYearCHD', y = 'heartRate', data = data)
plt.subplot(3,3,7)
sns.boxplot(x = 'TenYearCHD', y = 'glucose', data = data)
plt.subplot(3,3,8)
sns.boxplot(x = 'TenYearCHD', y = 'education', data = data)
plt.subplot(3,3,9)
sns.boxplot(x = 'TenYearCHD', y = 'cigsPerDay', data = data)
plt.show()

# --- Code cell 20 ---

plt.figure(figsize=(20, 12))
plt.subplot(2,3,1)
sns.countplot(x ='male', hue = 'TenYearCHD', data = data)
plt.subplot(2,3,2)
sns.countplot(x ='currentSmoker', hue = 'TenYearCHD', data = data)
plt.subplot(2,3,3)
sns.countplot(x ='BPMeds', hue = 'TenYearCHD', data = data)
plt.subplot(2,3,4)
sns.countplot(x ='prevalentStroke', hue = 'TenYearCHD', data = data)
plt.subplot(2,3,5)
sns.countplot(x ='prevalentHyp', hue = 'TenYearCHD', data = data)
plt.subplot(2,3,6)
sns.countplot(x ='diabetes', hue = 'TenYearCHD', data = data)
plt.show()

# --- Code cell 21 ---
len(data.columns)

# --- Code cell 22 ---
#Correlation of output with numerical variables
numerical_columns = ['age', 'cigsPerDay', 'totChol', 'BMI','heartRate', 'glucose', 'sysBP','diaBP']

# plotting correlation heatmap
dataplot = sns.heatmap(data[numerical_columns].corr(), cmap="YlGnBu", annot=True)

# --- Code cell 23 ---
# Highly correlated features

#sysBP: Systolic Blood Pressure - The pressure exerted when the heartbeats
#diaBP: Diastolic Blood Pressure - The pressure exerted on the walls of the arteries when the heart muscles relax 
#in between two beats

#Both systolic and diastolic blood pressure are important indicators of cardiovascular health, 
#and both can be associated with an increased risk of heart disease. 

# However, the relationship between blood pressure and heart disease is complex, 
#and both systolic and diastolic pressure readings are often considered together 
# to provide a more comprehensive assessment.

# --- Code cell 26 ---
data.head(10)

# --- Code cell 30 ---
def train_test_split_and_scale(data):
    y = data["TenYearCHD"]
    x = data.drop('TenYearCHD',axis=1)
    features = list(x.columns)
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state = 0)
    scaler = MinMaxScaler()
    x_train = scaler.fit_transform(x_train) # scaling is done only on features
    x_test = scaler.transform(x_test)
    return x_train, x_test, y_train, y_test,features

# --- Code cell 31 ---
x_train, x_test, y_train, y_test,features = train_test_split_and_scale(data)

# --- Code cell 32 ---
Counter(y_train)

# --- Code cell 33 ---
def fit_and_evaluate_model(x_train, x_test, y_train, y_test,class_weight=None):
    lr = LogisticRegression(class_weight=class_weight)
    model = lr.fit(x_train, y_train) # model training
    lr_predict = lr.predict(x_test) # create predicted o/p 0/1
    lr_conf_matrix = confusion_matrix(y_test, lr_predict)
    lr_acc_score = accuracy_score(y_test, lr_predict)
    print("confussion matrix")
    print(lr_conf_matrix)
    print("\n")
    print("Accuracy of Logistic Regression:",lr_acc_score*100,'\n')
    print(classification_report(y_test,lr_predict))
    return model

# --- Code cell 34 ---
model = fit_and_evaluate_model(x_train, x_test, y_train, y_test)
print("odds ratio", np.exp(model.coef_))

# --- Code cell 36 ---
Counter(y_train)

# --- Code cell 37 ---
Counter(y_test)

# --- Code cell 41 ---
# define class weights
weight = {0:1, 1:4}
model = fit_and_evaluate_model(x_train, x_test, y_train, y_test,class_weight=weight)

# --- Code cell 42 ---
results = pd.DataFrame(model.predict_proba(x_test))
results.columns = ['class_0_proba','class_1_proba']
results['predicted_class'] = model.predict(x_test)
results.head(10)

# --- Code cell 43 ---
#save and reuse the model

# --- Code cell 45 ---
import joblib  # 'pip install joblib' if you get "Package Not found Error"
joblib.dump(model , 'model_classifier.pkl')

# --- Code cell 46 ---
print(model_read.intercept_)

# --- Code cell 47 ---
model_read = joblib.load('model_classifier.pkl')
model_read.predict(x_test)

# --- Code cell 49 ---
# Feature importance
# Odds ratio well higher than 1: Increase in fetaure value increases probability of event(heart risk) hapenning

# Odds ratio well below 1: Increase in fetaure value decreases probability of event(heart risk) hapenning

# A feature with an odds ratio near zero typically suggests that the associated predictor has 
#a strong negative impact on the odds of the event occurring.

# Odds ratio near 1 indicates that feature may not be a strong predictor

# --- Code cell 50 ---
odds_ratio = np.exp(model.coef_)[0]

for z in range(len(features)):
     print("Odds ratio for feature {} is {}".format(features[z], odds_ratio[z]))

# --- Code cell 52 ---
print(model.coef_)

# --- Code cell 53 ---
print(np.exp(model.coef_))
</pre>
                </div>
            </div>


            <div class="section" style="margin-top: 2rem;">
                <h2>Complete code from course notebook: logistic_regression.ipynb</h2>
                <p>Every line of code from the course notebook (verbatim).</p>
                <div class="code-block" style="max-height: 600px; overflow: auto;">
                    <pre style="white-space: pre; font-size: 0.85em;"># --- Code cell 1 ---
from IPython.core.display import HTML

HTML("""
&lt;style&gt;

h1 { color: blue !important; }
h2 { color: green !important; }
&lt;/style&gt;
""")

# --- Code cell 2 ---
import pandas as pd
#import ydata_profiling as yp
# data preprocessing
from sklearn.preprocessing import StandardScaler
# data splitting
from sklearn.model_selection import train_test_split
from collections import Counter
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report
import seaborn as sns
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np

# --- Code cell 3 ---
data = pd.read_csv("dataset.csv")

# --- Code cell 5 ---
# Sex: male or female
# Age: Age of the patient
# Current Smoker: whether or not the patient is a current smoker 
# Cigs Per Day: the number of cigarettes that the person smoked on average in one day
# BP Meds: whether or not the patient was on blood pressure medication 
# Prevalent Stroke: whether or not the patient had previously had a stroke 
# Prevalent Hyp: whether or not the patient was hypertensive 
# Diabetes: whether or not the patient had diabetes
# Tot Chol: total cholesterol level 
# Sys BP: systolic blood pressure 
# Dia BP: diastolic blood pressure 
# BMI: Body Mass Index 
# Heart Rate: heart rate 
# Glucose: glucose level 

#Predict variable (desired target)
# 10 year risk of coronary heart disease CHD (binary: â€œ1â€, means â€œYesâ€, â€œ0â€ means â€œNoâ€)

# --- Code cell 6 ---
data.head(10)

# --- Code cell 8 ---
data.info()

# --- Code cell 9 ---
print(data.isnull().sum())

# --- Code cell 10 ---
for col in data.columns:
    print(col)
    print(data[col].unique())
    print('\n')

# --- Code cell 12 ---
#categorical_columns = ['education','BPMeds']
numerical_columns = ['cigsPerDay', 'totChol', 'BMI','heartRate', 'glucose']


for column in list(numerical_columns):
   data[column].fillna(data[column].median(),inplace = True)

# --- Code cell 13 ---
print(data.isnull().sum())

# --- Code cell 16 ---
data.head(10)

# --- Code cell 17 ---
# What if we had patinet number column?
# Would that be useful as feature
# Drop such columns from data

# --- Code cell 18 ---
data.columns

# --- Code cell 19 ---
#Visualizing numerical variables

plt.figure(figsize=(20, 12))
plt.subplot(3,3,1)
sns.boxplot(x = 'TenYearCHD', y = 'age', data = data)
plt.subplot(3,3,2)
sns.boxplot(x = 'TenYearCHD', y = 'totChol', data = data)
plt.subplot(3,3,3)
sns.boxplot(x = 'TenYearCHD', y = 'sysBP', data = data)
plt.subplot(3,3,4)
sns.boxplot(x = 'TenYearCHD', y = 'diaBP', data = data)
plt.subplot(3,3,5)
sns.boxplot(x = 'TenYearCHD', y = 'BMI', data = data)
plt.subplot(3,3,6)
sns.boxplot(x = 'TenYearCHD', y = 'heartRate', data = data)
plt.subplot(3,3,7)
sns.boxplot(x = 'TenYearCHD', y = 'glucose', data = data)
plt.subplot(3,3,8)
sns.boxplot(x = 'TenYearCHD', y = 'education', data = data)
plt.subplot(3,3,9)
sns.boxplot(x = 'TenYearCHD', y = 'cigsPerDay', data = data)
plt.show()

# --- Code cell 20 ---

plt.figure(figsize=(20, 12))
plt.subplot(2,3,1)
sns.countplot(x ='male', hue = 'TenYearCHD', data = data)
plt.subplot(2,3,2)
sns.countplot(x ='currentSmoker', hue = 'TenYearCHD', data = data)
plt.subplot(2,3,3)
sns.countplot(x ='BPMeds', hue = 'TenYearCHD', data = data)
plt.subplot(2,3,4)
sns.countplot(x ='prevalentStroke', hue = 'TenYearCHD', data = data)
plt.subplot(2,3,5)
sns.countplot(x ='prevalentHyp', hue = 'TenYearCHD', data = data)
plt.subplot(2,3,6)
sns.countplot(x ='diabetes', hue = 'TenYearCHD', data = data)
plt.show()

# --- Code cell 21 ---
len(data.columns)

# --- Code cell 22 ---
#Correlation of output with numerical variables
numerical_columns = ['age', 'cigsPerDay', 'totChol', 'BMI','heartRate', 'glucose', 'sysBP','diaBP']

# plotting correlation heatmap
dataplot = sns.heatmap(data[numerical_columns].corr(), cmap="YlGnBu", annot=True)

# --- Code cell 23 ---
# Highly correlated features

#sysBP: Systolic Blood Pressure - The pressure exerted when the heartbeats
#diaBP: Diastolic Blood Pressure - The pressure exerted on the walls of the arteries when the heart muscles relax 
#in between two beats

#Both systolic and diastolic blood pressure are important indicators of cardiovascular health, 
#and both can be associated with an increased risk of heart disease. 

# However, the relationship between blood pressure and heart disease is complex, 
#and both systolic and diastolic pressure readings are often considered together 
# to provide a more comprehensive assessment.

# --- Code cell 26 ---
data.head(10)

# --- Code cell 30 ---
def train_test_split_and_scale(data):
    y = data["TenYearCHD"]
    x = data.drop('TenYearCHD',axis=1)
    features = list(x.columns)
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state = 0)
    scaler = MinMaxScaler()
    x_train = scaler.fit_transform(x_train) # scaling is done only on features
    x_test = scaler.transform(x_test)
    return x_train, x_test, y_train, y_test,features

# --- Code cell 31 ---
x_train, x_test, y_train, y_test,features = train_test_split_and_scale(data)

# --- Code cell 32 ---
Counter(y_train)

# --- Code cell 33 ---
def fit_and_evaluate_model(x_train, x_test, y_train, y_test,class_weight=None):
    lr = LogisticRegression(class_weight=class_weight)
    model = lr.fit(x_train, y_train) # model training
    lr_predict = lr.predict(x_test) # create predicted o/p 0/1
    lr_conf_matrix = confusion_matrix(y_test, lr_predict)
    lr_acc_score = accuracy_score(y_test, lr_predict)
    print("confussion matrix")
    print(lr_conf_matrix)
    print("\n")
    print("Accuracy of Logistic Regression:",lr_acc_score*100,'\n')
    print(classification_report(y_test,lr_predict))
    return model

# --- Code cell 34 ---
model = fit_and_evaluate_model(x_train, x_test, y_train, y_test)
print("odds ratio", np.exp(model.coef_))

# --- Code cell 36 ---
Counter(y_train)

# --- Code cell 37 ---
Counter(y_test)

# --- Code cell 41 ---
# define class weights
weight = {0:1, 1:4}
model = fit_and_evaluate_model(x_train, x_test, y_train, y_test,class_weight=weight)

# --- Code cell 42 ---
results = pd.DataFrame(model.predict_proba(x_test))
results.columns = ['class_0_proba','class_1_proba']
results['predicted_class'] = model.predict(x_test)
results.head(10)

# --- Code cell 43 ---
#save and reuse the model

# --- Code cell 45 ---
import joblib  # 'pip install joblib' if you get "Package Not found Error"
joblib.dump(model , 'model_classifier.pkl')

# --- Code cell 46 ---
print(model_read.intercept_)

# --- Code cell 47 ---
model_read = joblib.load('model_classifier.pkl')
model_read.predict(x_test)

# --- Code cell 49 ---
# Feature importance
# Odds ratio well higher than 1: Increase in fetaure value increases probability of event(heart risk) hapenning

# Odds ratio well below 1: Increase in fetaure value decreases probability of event(heart risk) hapenning

# A feature with an odds ratio near zero typically suggests that the associated predictor has 
#a strong negative impact on the odds of the event occurring.

# Odds ratio near 1 indicates that feature may not be a strong predictor

# --- Code cell 50 ---
odds_ratio = np.exp(model.coef_)[0]

for z in range(len(features)):
     print("Odds ratio for feature {} is {}".format(features[z], odds_ratio[z]))

# --- Code cell 52 ---
print(model.coef_)

# --- Code cell 53 ---
print(np.exp(model.coef_))
</pre>
                </div>
            </div>

            <div class="reflection-prompt" style="background: linear-gradient(135deg, #fce7f3 0%, #fbcfe8 100%); border-radius: 16px; padding: 24px; margin: 25px 0; border-left: 5px solid #db2777;">
                <h4 style="color: #be185d;">ğŸ’­ Short reflection</h4><div class="reflection-prompt" style="background: linear-gradient(135deg, #fce7f3 0%, #fbcfe8 100%); border-radius: 16px; padding: 24px; margin: 25px 0; border-left: 5px solid #db2777;">
                <h4 style="color: #be185d;">ğŸ’­ Short reflection</h4>
                <p style="color: #831843;">In one sentence: why canâ€™t we use linear regression for binary classification (0/1) instead of logistic regression?</p>
            </div>

            <div class="core-box" style="background: linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%); border: 2px solid #22c55e; border-radius: 16px; padding: 24px; margin: 20px 0;">
                <h4 style="color: #166534;">âœ… CORE (Must know)</h4>
                <ul style="margin-left: 20px;">
                    <li><strong>Logistic regression</strong>: predicts probability P(Y=1) via sigmoid(z); z = linear combination of features.</li>
                    <li><strong>Sigmoid</strong>: 1/(1+e^(-z)); squashes output to (0,1).</li>
                    <li><strong>Decision boundary</strong>: typically 0.5; tune threshold for precision/recall tradeoff.</li>
                    <li><strong>Confusion matrix</strong>: TN, FP, FN, TP; precision = TP/(TP+FP), recall = TP/(TP+FN), F1 = harmonic mean.</li>
                    <li><strong>Imbalanced data</strong>: use class_weight, F1, or AUC-ROC; donâ€™t rely on accuracy alone.</li>
                    <li>Interpret coefficients as log-odds; odds ratio = e^coefficient.</li>
                </ul>
            </div>
            <div class="noncore-box" style="background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%); border: 2px solid #f59e0b; border-radius: 16px; padding: 24px; margin: 20px 0;">
                <h4 style="color: #92400e;">ğŸ“š NON-CORE (Good to know)</h4>
                <ul style="margin-left: 20px;">
                    <li>Log-loss (cross-entropy) as the cost function.</li>
                    <li>Multiclass: softmax and one-vs-rest.</li>
                    <li>Regularization (L1/L2) in logistic regression.</li>
                </ul>
            </div>
        </div>

        <!-- CHAPTER 9: SUMMARY -->
        <div class="section">
            <h2><i class="fas fa-graduation-cap"></i> Summary</h2>
            
            <table class="data-table">
                <tr>
                    <th>Concept</th>
                    <th>Simple Explanation</th>
                </tr>
                <tr>
                    <td><strong>Logistic Regression</strong></td>
                    <td>Predicts probability of belonging to a class (0-1)</td>
                </tr>
                <tr>
                    <td><strong>Sigmoid Function</strong></td>
                    <td>S-shaped curve that squishes values between 0 and 1</td>
                </tr>
                <tr>
                    <td><strong>Confusion Matrix</strong></td>
                    <td>Shows TP, TN, FP, FN - where model makes mistakes</td>
                </tr>
                <tr>
                    <td><strong>Accuracy</strong></td>
                    <td>% of correct predictions (can be misleading!)</td>
                </tr>
                <tr>
                    <td><strong>Recall</strong></td>
                    <td>Of actual positives, how many did we catch?</td>
                </tr>
                <tr>
                    <td><strong>Precision</strong></td>
                    <td>Of predicted positives, how many were correct?</td>
                </tr>
                <tr>
                    <td><strong>Class Weights</strong></td>
                    <td>Fix imbalanced data by penalizing minority class mistakes more</td>
                </tr>
                <tr>
                    <td><strong>Odds Ratio</strong></td>
                    <td>How much each feature increases/decreases risk</td>
                </tr>
            </table>

            <div class="visual-example">
                <h4>ğŸ‰ You've Mastered Logistic Regression!</h4>
                <p>You can now build classification models for healthcare, finance, marketing, and more!</p>
            </div>
        </div>

        <div class="nav-buttons">
            <a href="bias-variance.html" class="nav-btn prev"><i class="fas fa-arrow-left"></i> Previous: Bias & Variance</a>
            <a href="index.html" class="nav-btn next">Back to Course Hub <i class="fas fa-arrow-right"></i></a>
        </div>
    </div>

    <button class="back-to-top" id="backToTop"><i class="fas fa-arrow-up"></i></button>
    <script>
        const backToTopButton = document.getElementById('backToTop');
        window.addEventListener('scroll', () => {
            if (window.pageYOffset > 300) backToTopButton.classList.add('show');
            else backToTopButton.classList.remove('show');
        });
        backToTopButton.addEventListener('click', () => window.scrollTo({ top: 0, behavior: 'smooth' }));
    </script>
</body>
</html>
