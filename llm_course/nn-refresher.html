<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Network Refresher | LLM Course | Fakhruddin Khambaty's Learning Hub</title>
    <link href="https://fonts.googleapis.com/css2?family=Nunito:wght@400;500;600;700;800;900&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'Nunito', sans-serif;
            background: linear-gradient(160deg, #f5f0ff 0%, #ede4ff 25%, #e8f4fd 50%, #fdf2f8 75%, #f0f9ff 100%);
            background-attachment: fixed;
            min-height: 100vh; padding: 20px; color: #1e293b; line-height: 2; font-size: 18px;
        }
        .container { max-width: 900px; margin: 0 auto; }
        .nav {
            background: rgba(255,255,255,0.65); backdrop-filter: blur(20px);
            border: 1px solid rgba(139,92,246,0.12); padding: 15px 30px; border-radius: 18px;
            margin-bottom: 30px; box-shadow: 0 4px 24px rgba(139,92,246,0.06);
            display: flex; justify-content: space-between; align-items: center; flex-wrap: wrap; gap: 12px;
        }
        .nav a { color: #6d28d9; text-decoration: none; font-weight: 600; display: flex; align-items: center; gap: 8px; }
        .header {
            text-align: center; padding: 55px 40px;
            background: linear-gradient(135deg, #ec4899 0%, #db2777 50%, #be185d 100%);
            border-radius: 28px; color: white; margin-bottom: 40px;
            box-shadow: 0 12px 40px rgba(219,39,119,0.25);
        }
        .header h1 { font-size: 2.5em; margin-bottom: 15px; font-weight: 900; }
        .header p { font-size: 1.15em; opacity: 0.95; max-width: 700px; margin: 0 auto; }
        .badge { background: #f59e0b; color: white; padding: 8px 20px; border-radius: 25px; font-weight: 700; display: inline-block; margin-bottom: 20px; font-size: 0.9em; }
        .section {
            background: rgba(255,255,255,0.6); backdrop-filter: blur(18px);
            border: 1px solid rgba(139,92,246,0.1); border-radius: 28px;
            padding: 45px; margin-bottom: 35px;
            box-shadow: 0 4px 30px rgba(139,92,246,0.05);
        }
        .section h2 { color: #be185d; font-size: 1.8em; margin-bottom: 25px; display: flex; align-items: center; gap: 15px; padding-bottom: 15px; border-bottom: 3px solid #fce7f3; }
        .section h3 { color: #9d174d; font-size: 1.35em; margin: 35px 0 20px 0; padding-left: 20px; border-left: 5px solid #ec4899; }
        .section p { font-size: 1.08em; color: #334155; margin-bottom: 18px; }
        .eli5 {
            background: linear-gradient(135deg, #fffbeb, #fef3c7); border: 2px dashed #f59e0b;
            border-radius: 20px; padding: 28px; margin: 25px 0;
        }
        .eli5 h4 { color: #92400e; font-size: 1.25em; margin-bottom: 15px; }
        .eli5 p { color: #78350f; font-size: 1.1em; margin-bottom: 10px; }
        .analogy {
            background: linear-gradient(135deg, #fdf2f8, #fce7f3);
            border-left: 5px solid #ec4899; border-radius: 20px; padding: 28px; margin: 25px 0;
        }
        .analogy h4 { color: #9d174d; font-size: 1.2em; margin-bottom: 15px; }
        .analogy p { color: #831843; }
        .key-point {
            background: linear-gradient(135deg, #fdf2f8, #fce7f3);
            border-left: 5px solid #ec4899; border-radius: 20px; padding: 25px; margin: 25px 0;
        }
        .key-point h4 { color: #9d174d; margin-bottom: 12px; }
        .key-point ul { margin-left: 22px; color: #831843; }
        .key-point li { margin-bottom: 8px; }
        .visual {
            background: rgba(255,255,255,0.5); backdrop-filter: blur(12px);
            border: 1px solid #fbcfe8; border-radius: 20px; padding: 30px; margin: 25px 0; text-align: center;
        }
        .visual h4 { color: #be185d; margin-bottom: 15px; }
        .visual svg { max-width: 100%; height: auto; }
        .code-block {
            background: #1e293b; border-radius: 16px; padding: 25px; margin: 20px 0;
            overflow-x: auto; position: relative;
        }
        .code-block pre {
            font-family: 'Fira Code', monospace; font-size: 0.92em;
            color: #e2e8f0; line-height: 1.8; margin: 0; white-space: pre;
        }
        .code-block .comment { color: #64748b; }
        .code-block .keyword { color: #c084fc; }
        .code-block .string { color: #86efac; }
        .code-block .function { color: #7dd3fc; }
        .code-block .number { color: #fbbf24; }
        .code-block .builtin { color: #f9a8d4; }
        .code-block .label {
            position: absolute; top: 10px; right: 14px;
            background: rgba(255,255,255,0.08); color: #94a3b8;
            padding: 2px 10px; border-radius: 8px; font-size: 0.78em;
            font-family: 'Fira Code', monospace;
        }
        .playground {
            background: rgba(255,255,255,0.55); backdrop-filter: blur(14px);
            border: 1px solid #f9a8d4; border-radius: 22px; padding: 30px; margin: 30px 0; text-align: center;
        }
        .playground h4 { color: #be185d; margin-bottom: 8px; font-size: 1.15em; }
        .playground p { color: #334155; font-size: 0.95em; margin-bottom: 15px; }
        .nav-buttons { display: flex; justify-content: space-between; margin-top: 50px; gap: 20px; flex-wrap: wrap; }
        .nav-btn {
            display: inline-flex; align-items: center; gap: 10px;
            padding: 16px 32px; border-radius: 16px; text-decoration: none; font-weight: 700; transition: all .3s;
        }
        .nav-btn.prev { background: rgba(255,255,255,0.7); backdrop-filter: blur(10px); color: #475569; border: 1px solid #e2e8f0; }
        .nav-btn.next { background: linear-gradient(135deg, #ec4899, #db2777); color: white; box-shadow: 0 4px 20px rgba(219,39,119,0.25); }
        .nav-btn:hover { transform: translateY(-3px); }

        .slider-wrap { display: flex; align-items: center; gap: 14px; justify-content: center; flex-wrap: wrap; margin: 10px 0; }
        .slider-wrap label { font-weight: 700; color: #9d174d; min-width: 80px; text-align: right; }
        .slider-wrap input[type=range] {
            -webkit-appearance: none; width: 200px; height: 8px; border-radius: 4px;
            background: linear-gradient(90deg, #fce7f3, #ec4899); outline: none;
        }
        .slider-wrap input[type=range]::-webkit-slider-thumb {
            -webkit-appearance: none; width: 22px; height: 22px; border-radius: 50%;
            background: #db2777; cursor: pointer; box-shadow: 0 2px 8px rgba(219,39,119,0.3);
        }
        .slider-wrap .val { font-family: 'Fira Code', monospace; font-weight: 700; color: #be185d; min-width: 50px; }

        .step-badge {
            display: inline-block; background: #db2777; color: white; width: 32px; height: 32px;
            line-height: 32px; border-radius: 50%; text-align: center; font-weight: 800; font-size: 0.9em;
            margin-right: 10px;
        }

        @keyframes flowDot {
            0% { offset-distance: 0%; opacity: 0; }
            10% { opacity: 1; }
            90% { opacity: 1; }
            100% { offset-distance: 100%; opacity: 0; }
        }
        @keyframes pulseNode {
            0%, 100% { r: 18; }
            50% { r: 22; }
        }
        @keyframes fadeInUp {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }
        @keyframes drawLoss {
            from { stroke-dashoffset: 600; }
            to { stroke-dashoffset: 0; }
        }
        @keyframes loopHighlight {
            0%, 100% { opacity: 0.3; }
            20% { opacity: 1; }
            40% { opacity: 0.3; }
        }

        @media (max-width: 768px) {
            body { padding: 10px; font-size: 16px; }
            .header { padding: 30px 20px; } .header h1 { font-size: 1.8em; }
            .section { padding: 25px 18px; }
            .nav-buttons { flex-direction: column; }
            .slider-wrap { flex-direction: column; gap: 6px; }
            .slider-wrap input[type=range] { width: 100%; }
        }
    </style>
</head>
<body>
<div class="container">
    <nav class="nav">
        <a href="index.html"><i class="fas fa-arrow-left"></i> Course Hub</a>
        <a href="../index.html"><i class="fas fa-home"></i> Home</a>
    </nav>

    <div class="header">
        <span class="badge">Module 3 ‚Äî Building Blocks</span>
        <h1>üß† Neural Network Refresher</h1>
        <p>Fast-track the building blocks that LLMs use. No PhD required ‚Äî just analogies, visuals, and code you can actually run.</p>
    </div>

    <!-- ========== PART 1: What is a Neural Network? ========== -->
    <div class="section" id="what">
        <h2><i class="fas fa-project-diagram"></i> Part 1: What is a Neural Network?</h2>

        <div class="eli5">
            <h4>üë∂ Like You're 5</h4>
            <p>A neural network is a program that learns by example. You show it thousands of examples ("this picture is a cat", "this picture is a dog"), and it figures out the <strong>patterns</strong> ‚Äî pointy ears, whiskers, fur color ‚Äî all on its own. You never tell it the rules; it discovers them.</p>
            <p>It's called "neural" because it was loosely inspired by how brain cells (neurons) connect to each other. But don't overthink that ‚Äî it's really just <strong>math</strong> organized in layers.</p>
        </div>

        <div class="analogy">
            <h4>üè≠ The Factory Assembly Line</h4>
            <p>Imagine a factory with assembly lines. Raw materials (your data) enter on one end. At each station, <strong>workers</strong> (neurons) look at what they receive, do a small transformation, and pass the result to the next station. The first station might notice edges, the second notices shapes, the third recognizes faces. By the end of the line, the factory produces a finished product (a prediction). Each worker has a set of <strong>knobs</strong> (weights) that control how they transform the data. Training = turning those knobs until the factory produces correct answers.</p>
        </div>

        <!-- Animated SVG: Neural Network Architecture -->
        <div class="visual">
            <h4>üé¨ How Data Flows Through a Neural Network</h4>
            <svg viewBox="0 0 750 340" xmlns="http://www.w3.org/2000/svg" id="nnDiagram">
                <rect width="750" height="340" rx="16" fill="#fefce8" fill-opacity="0.3"/>

                <text x="100" y="30" text-anchor="middle" fill="#be185d" font-size="13" font-weight="800" font-family="Nunito">Input</text>
                <text x="310" y="30" text-anchor="middle" fill="#be185d" font-size="13" font-weight="800" font-family="Nunito">Hidden Layer 1</text>
                <text x="500" y="30" text-anchor="middle" fill="#be185d" font-size="13" font-weight="800" font-family="Nunito">Hidden Layer 2</text>
                <text x="660" y="30" text-anchor="middle" fill="#be185d" font-size="13" font-weight="800" font-family="Nunito">Output</text>

                <!-- Connection lines -->
                <g stroke="#f9a8d4" stroke-width="1.5" opacity="0.5">
                    <!-- Input to Hidden 1 -->
                    <line x1="130" y1="90" x2="270" y2="70"/><line x1="130" y1="90" x2="270" y2="140"/>
                    <line x1="130" y1="90" x2="270" y2="210"/><line x1="130" y1="90" x2="270" y2="280"/>
                    <line x1="130" y1="170" x2="270" y2="70"/><line x1="130" y1="170" x2="270" y2="140"/>
                    <line x1="130" y1="170" x2="270" y2="210"/><line x1="130" y1="170" x2="270" y2="280"/>
                    <line x1="130" y1="250" x2="270" y2="70"/><line x1="130" y1="250" x2="270" y2="140"/>
                    <line x1="130" y1="250" x2="270" y2="210"/><line x1="130" y1="250" x2="270" y2="280"/>
                    <!-- Hidden 1 to Hidden 2 -->
                    <line x1="350" y1="70" x2="460" y2="100"/><line x1="350" y1="70" x2="460" y2="190"/>
                    <line x1="350" y1="70" x2="460" y2="280"/>
                    <line x1="350" y1="140" x2="460" y2="100"/><line x1="350" y1="140" x2="460" y2="190"/>
                    <line x1="350" y1="140" x2="460" y2="280"/>
                    <line x1="350" y1="210" x2="460" y2="100"/><line x1="350" y1="210" x2="460" y2="190"/>
                    <line x1="350" y1="210" x2="460" y2="280"/>
                    <line x1="350" y1="280" x2="460" y2="100"/><line x1="350" y1="280" x2="460" y2="190"/>
                    <line x1="350" y1="280" x2="460" y2="280"/>
                    <!-- Hidden 2 to Output -->
                    <line x1="540" y1="100" x2="630" y2="170"/>
                    <line x1="540" y1="190" x2="630" y2="170"/>
                    <line x1="540" y1="280" x2="630" y2="170"/>
                </g>

                <!-- Input neurons -->
                <circle cx="100" cy="90" r="18" fill="#fce7f3" stroke="#ec4899" stroke-width="2.5"><animate attributeName="r" values="18;22;18" dur="2s" repeatCount="indefinite" begin="0s"/></circle>
                <text x="100" y="95" text-anchor="middle" fill="#9d174d" font-size="11" font-weight="800" font-family="Nunito">x‚ÇÅ</text>
                <circle cx="100" cy="170" r="18" fill="#fce7f3" stroke="#ec4899" stroke-width="2.5"><animate attributeName="r" values="18;22;18" dur="2s" repeatCount="indefinite" begin="0.3s"/></circle>
                <text x="100" y="175" text-anchor="middle" fill="#9d174d" font-size="11" font-weight="800" font-family="Nunito">x‚ÇÇ</text>
                <circle cx="100" cy="250" r="18" fill="#fce7f3" stroke="#ec4899" stroke-width="2.5"><animate attributeName="r" values="18;22;18" dur="2s" repeatCount="indefinite" begin="0.6s"/></circle>
                <text x="100" y="255" text-anchor="middle" fill="#9d174d" font-size="11" font-weight="800" font-family="Nunito">x‚ÇÉ</text>

                <!-- Hidden 1 neurons -->
                <circle cx="310" cy="70" r="18" fill="#fdf2f8" stroke="#db2777" stroke-width="2"/><text x="310" y="75" text-anchor="middle" fill="#9d174d" font-size="10" font-weight="700" font-family="Nunito">h‚ÇÅ</text>
                <circle cx="310" cy="140" r="18" fill="#fdf2f8" stroke="#db2777" stroke-width="2"/><text x="310" y="145" text-anchor="middle" fill="#9d174d" font-size="10" font-weight="700" font-family="Nunito">h‚ÇÇ</text>
                <circle cx="310" cy="210" r="18" fill="#fdf2f8" stroke="#db2777" stroke-width="2"/><text x="310" y="215" text-anchor="middle" fill="#9d174d" font-size="10" font-weight="700" font-family="Nunito">h‚ÇÉ</text>
                <circle cx="310" cy="280" r="18" fill="#fdf2f8" stroke="#db2777" stroke-width="2"/><text x="310" y="285" text-anchor="middle" fill="#9d174d" font-size="10" font-weight="700" font-family="Nunito">h‚ÇÑ</text>

                <!-- Hidden 2 neurons -->
                <circle cx="500" cy="100" r="18" fill="#fdf2f8" stroke="#db2777" stroke-width="2"/><text x="500" y="105" text-anchor="middle" fill="#9d174d" font-size="10" font-weight="700" font-family="Nunito">h‚ÇÖ</text>
                <circle cx="500" cy="190" r="18" fill="#fdf2f8" stroke="#db2777" stroke-width="2"/><text x="500" y="195" text-anchor="middle" fill="#9d174d" font-size="10" font-weight="700" font-family="Nunito">h‚ÇÜ</text>
                <circle cx="500" cy="280" r="18" fill="#fdf2f8" stroke="#db2777" stroke-width="2"/><text x="500" y="285" text-anchor="middle" fill="#9d174d" font-size="10" font-weight="700" font-family="Nunito">h‚Çá</text>

                <!-- Output neuron -->
                <circle cx="660" cy="170" r="22" fill="#dcfce7" stroke="#22c55e" stroke-width="2.5"><animate attributeName="r" values="22;26;22" dur="2.5s" repeatCount="indefinite"/></circle>
                <text x="660" y="175" text-anchor="middle" fill="#166534" font-size="11" font-weight="800" font-family="Nunito">≈∑</text>

                <!-- Animated dots flowing through the network -->
                <circle r="5" fill="#ec4899">
                    <animateMotion dur="2.5s" repeatCount="indefinite" path="M100,90 L310,140 L500,190 L660,170" begin="0s"/>
                    <animate attributeName="opacity" values="0;1;1;0" dur="2.5s" repeatCount="indefinite" begin="0s"/>
                </circle>
                <circle r="5" fill="#db2777">
                    <animateMotion dur="2.5s" repeatCount="indefinite" path="M100,170 L310,70 L500,100 L660,170" begin="0.8s"/>
                    <animate attributeName="opacity" values="0;1;1;0" dur="2.5s" repeatCount="indefinite" begin="0.8s"/>
                </circle>
                <circle r="5" fill="#be185d">
                    <animateMotion dur="2.5s" repeatCount="indefinite" path="M100,250 L310,280 L500,280 L660,170" begin="1.6s"/>
                    <animate attributeName="opacity" values="0;1;1;0" dur="2.5s" repeatCount="indefinite" begin="1.6s"/>
                </circle>

                <!-- Labels -->
                <text x="35" y="90" text-anchor="middle" fill="#6b7280" font-size="9" font-family="Nunito">sqft</text>
                <text x="35" y="170" text-anchor="middle" fill="#6b7280" font-size="9" font-family="Nunito">beds</text>
                <text x="35" y="250" text-anchor="middle" fill="#6b7280" font-size="9" font-family="Nunito">age</text>
                <text x="715" y="175" text-anchor="middle" fill="#6b7280" font-size="9" font-family="Nunito">price</text>

                <rect x="180" y="305" width="400" height="28" rx="10" fill="#fef9c3" opacity="0.8"/>
                <text x="380" y="324" text-anchor="middle" fill="#92400e" font-size="10" font-weight="700" font-family="Nunito">‚¨§ Watch the dots flow! Each dot = a piece of data moving through the network</text>
            </svg>
        </div>

        <h3>Inside a Single Neuron</h3>
        <p>Every neuron in the network does the same simple thing: take inputs, multiply each by a <strong>weight</strong>, add a <strong>bias</strong>, then apply an <strong>activation function</strong>. That's it ‚Äî just multiply, add, squish.</p>

        <div class="analogy">
            <h4>üçΩÔ∏è The Restaurant Tip Calculator</h4>
            <p>Imagine you're calculating a tip. Your inputs are: <strong>food quality</strong> (1-10) and <strong>service quality</strong> (1-10). You care about service twice as much as food, so your weights are: food = 0.1, service = 0.2. You always tip at least 5%, so your bias = 5.</p>
            <p><strong>tip = (food √ó 0.1) + (service √ó 0.2) + 5</strong></p>
            <p>If food = 8 and service = 9: tip = (8√ó0.1) + (9√ó0.2) + 5 = 0.8 + 1.8 + 5 = <strong>7.6%</strong></p>
            <p>A neuron is exactly this! Multiply each input by its weight, add them up, add the bias, done. Training = adjusting those weights and bias until the predictions are correct.</p>
        </div>

        <!-- Interactive: Single Neuron Playground -->
        <div class="playground" id="neuronPlayground">
            <h4><i class="fas fa-sliders-h"></i> Interactive: Build a Neuron!</h4>
            <p>Drag the sliders to change inputs and weights. Watch the neuron compute its output in real time.</p>

            <div style="background:white;border-radius:16px;padding:24px;border:1px solid #fbcfe8;text-align:left;margin-bottom:15px;">
                <div class="slider-wrap">
                    <label>Input (x):</label>
                    <input type="range" min="0" max="10" step="0.5" value="5" id="sliderX" oninput="updateNeuron()">
                    <span class="val" id="valX">5.0</span>
                </div>
                <div class="slider-wrap">
                    <label>Weight (w):</label>
                    <input type="range" min="-2" max="2" step="0.1" value="0.7" id="sliderW" oninput="updateNeuron()">
                    <span class="val" id="valW">0.7</span>
                </div>
                <div class="slider-wrap">
                    <label>Bias (b):</label>
                    <input type="range" min="-3" max="3" step="0.1" value="0.5" id="sliderB" oninput="updateNeuron()">
                    <span class="val" id="valB">0.5</span>
                </div>

                <div style="text-align:center;margin-top:20px;">
                    <div style="font-family:'Fira Code',monospace;font-size:1.1em;color:#334155;margin-bottom:8px;">
                        z = x √ó w + b = <span id="calcZ" style="color:#be185d;font-weight:800;">4.00</span>
                    </div>
                    <div style="font-family:'Fira Code',monospace;font-size:1.1em;color:#334155;">
                        ReLU(z) = max(0, z) = <span id="calcRelu" style="color:#22c55e;font-weight:800;font-size:1.3em;">4.00</span>
                    </div>
                </div>

                <!-- Mini visualization bar -->
                <div style="margin-top:16px;background:#f1f5f9;border-radius:10px;height:24px;overflow:hidden;position:relative;">
                    <div id="reluBar" style="height:100%;background:linear-gradient(90deg,#ec4899,#22c55e);border-radius:10px;width:40%;transition:width 0.3s;"></div>
                    <span style="position:absolute;right:10px;top:2px;font-size:0.75em;font-weight:700;color:#475569;" id="reluBarLabel">4.00</span>
                </div>
            </div>
            <p style="font-size:0.88em;color:#6b7280;">üí° Try making the weight negative ‚Äî the neuron "flips" its response! Set bias very negative to see ReLU clamp to 0.</p>
        </div>

        <div class="key-point">
            <h4>üí° Key Takeaways</h4>
            <ul>
                <li>A neural network = layers of neurons connected together</li>
                <li>Each neuron computes: <strong>output = activation(inputs √ó weights + bias)</strong></li>
                <li><strong>Weights</strong> control how much each input matters</li>
                <li><strong>Bias</strong> shifts the output up or down</li>
                <li><strong>Activation function</strong> (like ReLU) adds non-linearity ‚Äî without it, the whole network would just be a fancy linear equation</li>
                <li>More layers = the network can learn more complex patterns</li>
            </ul>
        </div>
    </div>

    <!-- ========== PART 2: Forward Pass & Backpropagation ========== -->
    <div class="section" id="forward">
        <h2><i class="fas fa-exchange-alt"></i> Part 2: Forward Pass &amp; Backpropagation</h2>

        <p>Training a neural network is a two-step dance that repeats thousands of times: <strong>forward</strong> (make a prediction) and <strong>backward</strong> (learn from mistakes).</p>

        <h3>Forward Pass: Making a Prediction</h3>
        <p>Data flows from left to right through the network. Each layer transforms the data a little bit. At the end, you get a <strong>prediction</strong>. This is the forward pass ‚Äî just plugging numbers into the formula, layer by layer.</p>

        <div class="eli5">
            <h4>üë∂ Like You're 5</h4>
            <p>Imagine passing a message along a chain of friends. You whisper "5" to the first friend. They multiply by 2 and whisper "10" to the next. That friend adds 3 and whispers "13" to the next. And so on until the last friend shouts out the final answer. That's a forward pass!</p>
        </div>

        <h3>Loss: How Wrong Were We?</h3>
        <p>After the forward pass, we compare our prediction to the correct answer. The difference is called the <strong>loss</strong>. The bigger the loss, the worse our prediction. Our goal: <strong>minimize the loss</strong>.</p>

        <div class="analogy">
            <h4>üéØ The Dart Board</h4>
            <p>You throw a dart at a bullseye. The <strong>loss</strong> is the distance between where your dart landed and the center. A loss of 0 = perfect bullseye. Training = throwing darts over and over, adjusting your aim each time. The loss function is your tape measure ‚Äî it tells you exactly how far off you were.</p>
        </div>

        <h3>Backpropagation: Learning from Mistakes</h3>
        <p>After computing the loss, we need to figure out <strong>which weights caused the error</strong> and <strong>how to fix them</strong>. Backpropagation sends error signals backward through the network ‚Äî from output to input ‚Äî computing how much each weight contributed to the mistake.</p>

        <div class="analogy">
            <h4>üìù The Teacher Grading Papers</h4>
            <p>Imagine a student gets a math problem wrong. The teacher doesn't just say "wrong!" ‚Äî they trace back through the student's work: "You made an error in step 3, and that caused steps 4, 5, and 6 to be wrong too." The teacher gives <strong>specific feedback</strong> for each step: "Adjust step 3 a lot, step 2 a little, step 1 is fine." That's backpropagation ‚Äî it assigns blame proportionally to each weight.</p>
        </div>

        <!-- Animated SVG: Forward + Backward Pass -->
        <div class="visual">
            <h4>üé¨ Forward Pass (Blue) ‚Üí Loss ‚Üí Backward Pass (Red)</h4>
            <svg viewBox="0 0 750 300" xmlns="http://www.w3.org/2000/svg">
                <rect width="750" height="300" rx="16" fill="#fefce8" fill-opacity="0.3"/>
                <defs>
                    <marker id="arrBlue" markerWidth="8" markerHeight="6" refX="7" refY="3" orient="auto"><polygon points="0 0,8 3,0 6" fill="#3b82f6"/></marker>
                    <marker id="arrRed" markerWidth="8" markerHeight="6" refX="7" refY="3" orient="auto"><polygon points="0 0,8 3,0 6" fill="#ef4444"/></marker>
                </defs>

                <!-- Nodes -->
                <circle cx="80" cy="100" r="28" fill="#dbeafe" stroke="#3b82f6" stroke-width="2.5"/>
                <text x="80" y="105" text-anchor="middle" fill="#1e40af" font-size="11" font-weight="800" font-family="Nunito">Input</text>

                <circle cx="260" cy="100" r="28" fill="#dbeafe" stroke="#3b82f6" stroke-width="2.5"/>
                <text x="260" y="105" text-anchor="middle" fill="#1e40af" font-size="11" font-weight="800" font-family="Nunito">Hidden</text>

                <circle cx="440" cy="100" r="28" fill="#dbeafe" stroke="#3b82f6" stroke-width="2.5"/>
                <text x="440" y="105" text-anchor="middle" fill="#1e40af" font-size="11" font-weight="800" font-family="Nunito">Output</text>

                <rect x="560" y="72" width="100" height="56" rx="14" fill="#fef3c7" stroke="#f59e0b" stroke-width="2.5"/>
                <text x="610" y="95" text-anchor="middle" fill="#92400e" font-size="11" font-weight="800" font-family="Nunito">Loss</text>
                <text x="610" y="115" text-anchor="middle" fill="#b45309" font-size="9" font-family="Nunito">= |≈∑ - y|¬≤</text>

                <!-- Forward arrows (blue) -->
                <line x1="112" y1="90" x2="228" y2="90" stroke="#3b82f6" stroke-width="3" marker-end="url(#arrBlue)"/>
                <text x="170" y="82" text-anchor="middle" fill="#3b82f6" font-size="10" font-weight="700" font-family="Nunito">√ó w‚ÇÅ</text>

                <line x1="292" y1="90" x2="408" y2="90" stroke="#3b82f6" stroke-width="3" marker-end="url(#arrBlue)"/>
                <text x="350" y="82" text-anchor="middle" fill="#3b82f6" font-size="10" font-weight="700" font-family="Nunito">√ó w‚ÇÇ</text>

                <line x1="472" y1="90" x2="555" y2="90" stroke="#3b82f6" stroke-width="3" marker-end="url(#arrBlue)"/>

                <!-- Forward animated dot -->
                <circle r="6" fill="#3b82f6">
                    <animateMotion dur="3s" repeatCount="indefinite" path="M80,100 L260,100 L440,100 L610,100" begin="0s"/>
                    <animate attributeName="opacity" values="0;1;1;1;0" dur="3s" repeatCount="indefinite"/>
                </circle>

                <!-- Forward label -->
                <text x="350" y="55" text-anchor="middle" fill="#3b82f6" font-size="14" font-weight="900" font-family="Nunito">‚Üí FORWARD PASS ‚Üí</text>

                <!-- Backward arrows (red) -->
                <line x1="555" y1="140" x2="472" y2="160" stroke="#ef4444" stroke-width="3" marker-end="url(#arrRed)" stroke-dasharray="6,4"/>
                <line x1="408" y1="165" x2="292" y2="165" stroke="#ef4444" stroke-width="3" marker-end="url(#arrRed)" stroke-dasharray="6,4"/>
                <line x1="228" y1="165" x2="112" y2="165" stroke="#ef4444" stroke-width="3" marker-end="url(#arrRed)" stroke-dasharray="6,4"/>

                <text x="490" y="180" text-anchor="middle" fill="#ef4444" font-size="9" font-weight="700" font-family="Nunito">‚àÇL/‚àÇw‚ÇÇ</text>
                <text x="350" y="188" text-anchor="middle" fill="#ef4444" font-size="9" font-weight="700" font-family="Nunito">adjust w‚ÇÇ</text>
                <text x="170" y="188" text-anchor="middle" fill="#ef4444" font-size="9" font-weight="700" font-family="Nunito">adjust w‚ÇÅ</text>

                <!-- Backward animated dot -->
                <circle r="6" fill="#ef4444">
                    <animateMotion dur="3s" repeatCount="indefinite" path="M610,140 L440,165 L260,165 L80,165" begin="1.5s"/>
                    <animate attributeName="opacity" values="0;1;1;1;0" dur="3s" repeatCount="indefinite" begin="1.5s"/>
                </circle>

                <!-- Backward label -->
                <text x="350" y="225" text-anchor="middle" fill="#ef4444" font-size="14" font-weight="900" font-family="Nunito">‚Üê BACKPROPAGATION ‚Üê</text>

                <rect x="100" y="245" width="540" height="40" rx="12" fill="#fdf2f8"/>
                <text x="370" y="270" text-anchor="middle" fill="#9d174d" font-size="10" font-weight="700" font-family="Nunito">üîµ Blue = data flows forward to make a prediction  |  üî¥ Red = error flows backward to fix weights</text>
            </svg>
        </div>

        <div class="key-point">
            <h4>üí° The Big Picture</h4>
            <ul>
                <li><strong>Forward pass:</strong> data goes left ‚Üí right, producing a prediction</li>
                <li><strong>Loss:</strong> measures how wrong the prediction is</li>
                <li><strong>Backpropagation:</strong> error goes right ‚Üí left, computing gradients (how much to adjust each weight)</li>
                <li><strong>Gradient descent:</strong> actually updates the weights by a small step in the direction that reduces the loss</li>
                <li>Repeat this thousands of times ‚Üí the network gets better and better</li>
            </ul>
        </div>
    </div>

    <!-- ========== PART 3: PyTorch Crash Course ========== -->
    <div class="section" id="pytorch">
        <h2><i class="fab fa-python"></i> Part 3: PyTorch Crash Course</h2>

        <div class="eli5">
            <h4>üë∂ Like You're 5</h4>
            <p>PyTorch is like a <strong>super-powered calculator</strong> that can do math on huge tables of numbers really fast (using your GPU), AND it automatically figures out derivatives (gradients) for you. Instead of doing calculus by hand for backpropagation, PyTorch does it in one line: <code>loss.backward()</code>. It's the tool that every major AI lab uses.</p>
        </div>

        <h3>Tensors: The Building Block</h3>
        <p>A <strong>tensor</strong> is just a multi-dimensional array of numbers. Think of it as a NumPy array that can also run on GPUs. Scalars, vectors, matrices ‚Äî they're all tensors.</p>

        <div class="code-block">
            <span class="label">Python / PyTorch</span>
<pre><span class="keyword">import</span> torch

<span class="comment"># Scalar (0-D tensor)</span>
x = torch.<span class="function">tensor</span>(<span class="number">3.14</span>)

<span class="comment"># Vector (1-D tensor)</span>
v = torch.<span class="function">tensor</span>([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>])

<span class="comment"># Matrix (2-D tensor)</span>
m = torch.<span class="function">tensor</span>([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])

<span class="comment"># Random tensor (common for initializing weights)</span>
w = torch.<span class="function">randn</span>(<span class="number">3</span>, <span class="number">4</span>)  <span class="comment"># 3 rows, 4 cols, random normal</span>

<span class="comment"># Basic operations</span>
a = torch.<span class="function">tensor</span>([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>])
b = torch.<span class="function">tensor</span>([<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>])
<span class="builtin">print</span>(a + b)      <span class="comment"># tensor([5., 7., 9.])</span>
<span class="builtin">print</span>(a * b)      <span class="comment"># tensor([ 4., 10., 18.])  element-wise</span>
<span class="builtin">print</span>(a @ b)      <span class="comment"># tensor(32.)  dot product</span>

<span class="comment"># Move to GPU (if available)</span>
<span class="keyword">if</span> torch.cuda.<span class="function">is_available</span>():
    a = a.<span class="function">to</span>(<span class="string">'cuda'</span>)</pre>
        </div>

        <h3>Autograd: Automatic Differentiation</h3>
        <p>This is PyTorch's killer feature. Set <code>requires_grad=True</code> on a tensor, do any math you want, and PyTorch will automatically compute the gradient when you call <code>.backward()</code>.</p>

        <div class="code-block">
            <span class="label">Python / Autograd</span>
<pre><span class="comment"># Tell PyTorch to track gradients for this tensor</span>
x = torch.<span class="function">tensor</span>(<span class="number">3.0</span>, requires_grad=<span class="keyword">True</span>)

<span class="comment"># Do some math: y = x¬≤ + 2x + 1</span>
y = x**<span class="number">2</span> + <span class="number">2</span>*x + <span class="number">1</span>

<span class="comment"># Compute gradient: dy/dx = 2x + 2 = 2(3) + 2 = 8</span>
y.<span class="function">backward</span>()

<span class="builtin">print</span>(x.grad)  <span class="comment"># tensor(8.)  ‚Üê PyTorch computed this automatically!</span></pre>
        </div>

        <div class="analogy">
            <h4>ü™Ñ Why Autograd is Magic</h4>
            <p>Imagine you built a Rube Goldberg machine with 100 steps. Now someone asks: "If I push the first domino 1mm further, how much further will the ball at step 100 travel?" You'd have to trace through all 100 steps with calculus. With Autograd, PyTorch builds the machine, watches it run, and <strong>automatically</strong> computes the answer. That's how backpropagation works in practice ‚Äî Autograd handles all the chain-rule calculus for you.</p>
        </div>

        <div class="key-point">
            <h4>üí° PyTorch Cheat Sheet</h4>
            <ul>
                <li><code>torch.tensor(data)</code> ‚Äî create a tensor</li>
                <li><code>torch.randn(shape)</code> ‚Äî random tensor (normal distribution)</li>
                <li><code>tensor.to('cuda')</code> ‚Äî move to GPU</li>
                <li><code>requires_grad=True</code> ‚Äî track gradients</li>
                <li><code>loss.backward()</code> ‚Äî compute all gradients</li>
                <li><code>optimizer.step()</code> ‚Äî update weights</li>
                <li><code>optimizer.zero_grad()</code> ‚Äî reset gradients to zero</li>
            </ul>
        </div>
    </div>

    <!-- ========== PART 4: Training Loop ========== -->
    <div class="section" id="train">
        <h2><i class="fas fa-sync-alt"></i> Part 4: The Training Loop</h2>

        <p>Every neural network trains the same way: five steps that repeat over and over. Once you know this loop, you can train <strong>any</strong> neural network ‚Äî from a 10-neuron toy to GPT-4.</p>

        <div class="eli5">
            <h4>üë∂ Like You're 5</h4>
            <p>It's like learning to throw a basketball. You throw (forward pass), see how far you missed (loss), think about what went wrong (backward), adjust your form a little (update weights), and throw again (repeat). After 10,000 throws, you barely miss!</p>
        </div>

        <!-- Interactive: Animated Training Loop Diagram -->
        <div class="visual">
            <h4>üîÑ The Training Loop ‚Äî Watch Each Step Light Up</h4>
            <svg viewBox="0 0 500 500" xmlns="http://www.w3.org/2000/svg" id="trainLoop">
                <rect width="500" height="500" rx="16" fill="#fefce8" fill-opacity="0.2"/>

                <!-- Circular path for steps -->
                <circle cx="250" cy="250" r="160" fill="none" stroke="#fce7f3" stroke-width="4" stroke-dasharray="8,6"/>

                <!-- Step 1: Forward -->
                <g>
                    <circle cx="250" cy="88" r="42" fill="#dbeafe" stroke="#3b82f6" stroke-width="3">
                        <animate attributeName="opacity" values="0.35;1;0.35;0.35;0.35" dur="5s" repeatCount="indefinite"/>
                    </circle>
                    <text x="250" y="82" text-anchor="middle" fill="#1e40af" font-size="10" font-weight="800" font-family="Nunito">‚ë† Forward</text>
                    <text x="250" y="98" text-anchor="middle" fill="#1e40af" font-size="8.5" font-family="Nunito">≈∑ = model(x)</text>
                </g>

                <!-- Step 2: Loss -->
                <g>
                    <circle cx="402" cy="196" r="42" fill="#fef3c7" stroke="#f59e0b" stroke-width="3">
                        <animate attributeName="opacity" values="0.35;0.35;1;0.35;0.35" dur="5s" repeatCount="indefinite"/>
                    </circle>
                    <text x="402" y="190" text-anchor="middle" fill="#92400e" font-size="10" font-weight="800" font-family="Nunito">‚ë° Loss</text>
                    <text x="402" y="206" text-anchor="middle" fill="#92400e" font-size="8.5" font-family="Nunito">L = f(≈∑, y)</text>
                </g>

                <!-- Step 3: Backward -->
                <g>
                    <circle cx="345" cy="370" r="42" fill="#fee2e2" stroke="#ef4444" stroke-width="3">
                        <animate attributeName="opacity" values="0.35;0.35;0.35;1;0.35" dur="5s" repeatCount="indefinite"/>
                    </circle>
                    <text x="345" y="364" text-anchor="middle" fill="#991b1b" font-size="10" font-weight="800" font-family="Nunito">‚ë¢ Backward</text>
                    <text x="345" y="380" text-anchor="middle" fill="#991b1b" font-size="8.5" font-family="Nunito">L.backward()</text>
                </g>

                <!-- Step 4: Update -->
                <g>
                    <circle cx="155" cy="370" r="42" fill="#dcfce7" stroke="#22c55e" stroke-width="3">
                        <animate attributeName="opacity" values="0.35;0.35;0.35;0.35;1" dur="5s" repeatCount="indefinite"/>
                    </circle>
                    <text x="155" y="364" text-anchor="middle" fill="#166534" font-size="10" font-weight="800" font-family="Nunito">‚ë£ Update</text>
                    <text x="155" y="380" text-anchor="middle" fill="#166534" font-size="8.5" font-family="Nunito">optim.step()</text>
                </g>

                <!-- Step 5: Zero Grad -->
                <g>
                    <circle cx="98" cy="196" r="42" fill="#f3e8ff" stroke="#8b5cf6" stroke-width="3">
                        <animate attributeName="opacity" values="1;0.35;0.35;0.35;0.35" dur="5s" repeatCount="indefinite"/>
                    </circle>
                    <text x="98" y="190" text-anchor="middle" fill="#5b21b6" font-size="10" font-weight="800" font-family="Nunito">‚ë§ Zero</text>
                    <text x="98" y="206" text-anchor="middle" fill="#5b21b6" font-size="8.5" font-family="Nunito">zero_grad()</text>
                </g>

                <!-- Arrows between steps -->
                <defs>
                    <marker id="arrPink" markerWidth="8" markerHeight="6" refX="7" refY="3" orient="auto"><polygon points="0 0,8 3,0 6" fill="#ec4899"/></marker>
                </defs>
                <path d="M285,55 Q360,60 385,155" fill="none" stroke="#ec4899" stroke-width="2.5" marker-end="url(#arrPink)"/>
                <path d="M435,230 Q440,310 378,340" fill="none" stroke="#ec4899" stroke-width="2.5" marker-end="url(#arrPink)"/>
                <path d="M305,385 Q250,410 195,385" fill="none" stroke="#ec4899" stroke-width="2.5" marker-end="url(#arrPink)"/>
                <path d="M120,340 Q70,300 72,230" fill="none" stroke="#ec4899" stroke-width="2.5" marker-end="url(#arrPink)"/>
                <path d="M115,155 Q130,70 215,55" fill="none" stroke="#ec4899" stroke-width="2.5" marker-end="url(#arrPink)"/>

                <!-- Center label -->
                <text x="250" y="240" text-anchor="middle" fill="#be185d" font-size="15" font-weight="900" font-family="Nunito">EPOCH</text>
                <text x="250" y="262" text-anchor="middle" fill="#9d174d" font-size="10" font-family="Nunito">repeat 1,000s of times</text>

                <!-- Animated dot circling -->
                <circle r="7" fill="#ec4899">
                    <animateMotion dur="5s" repeatCount="indefinite" path="M250,88 Q370,60 402,196 Q440,320 345,370 Q250,410 155,370 Q70,300 98,196 Q130,70 250,88" begin="0s"/>
                </circle>
            </svg>
        </div>

        <h3>The Training Loop in Code</h3>
        <p>Here it is ‚Äî the 5-step loop distilled to its essence. Memorize this and you can train anything:</p>

        <div class="code-block">
            <span class="label">Python / Training Loop</span>
<pre><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">1000</span>):
    y_pred = <span class="function">model</span>(X)              <span class="comment"># ‚ë† Forward pass</span>
    loss = <span class="function">loss_fn</span>(y_pred, y)      <span class="comment"># ‚ë° Compute loss</span>
    loss.<span class="function">backward</span>()                <span class="comment"># ‚ë¢ Backpropagation</span>
    optimizer.<span class="function">step</span>()               <span class="comment"># ‚ë£ Update weights</span>
    optimizer.<span class="function">zero_grad</span>()           <span class="comment"># ‚ë§ Reset gradients</span></pre>
        </div>

        <!-- Animated Loss Curve -->
        <div class="visual">
            <h4>üìâ Watch the Loss Decrease Over Training</h4>
            <svg viewBox="0 0 600 280" xmlns="http://www.w3.org/2000/svg">
                <rect width="600" height="280" rx="16" fill="#fefce8" fill-opacity="0.3"/>

                <!-- Axes -->
                <line x1="60" y1="240" x2="570" y2="240" stroke="#9d174d" stroke-width="2"/>
                <line x1="60" y1="30" x2="60" y2="240" stroke="#9d174d" stroke-width="2"/>
                <text x="320" y="270" text-anchor="middle" fill="#9d174d" font-size="12" font-weight="700" font-family="Nunito">Epochs ‚Üí</text>
                <text x="22" y="140" text-anchor="middle" fill="#9d174d" font-size="12" font-weight="700" font-family="Nunito" transform="rotate(-90,22,140)">Loss ‚Üí</text>

                <!-- Grid lines -->
                <g stroke="#fce7f3" stroke-width="1">
                    <line x1="60" y1="80" x2="570" y2="80"/><line x1="60" y1="130" x2="570" y2="130"/>
                    <line x1="60" y1="180" x2="570" y2="180"/>
                </g>

                <!-- Epoch labels -->
                <text x="60" y="255" text-anchor="middle" fill="#6b7280" font-size="9" font-family="Nunito">0</text>
                <text x="187" y="255" text-anchor="middle" fill="#6b7280" font-size="9" font-family="Nunito">250</text>
                <text x="315" y="255" text-anchor="middle" fill="#6b7280" font-size="9" font-family="Nunito">500</text>
                <text x="443" y="255" text-anchor="middle" fill="#6b7280" font-size="9" font-family="Nunito">750</text>
                <text x="570" y="255" text-anchor="middle" fill="#6b7280" font-size="9" font-family="Nunito">1000</text>

                <!-- Loss curve (exponential decay shape) -->
                <path d="M60,50 Q120,60 150,100 Q200,160 260,190 Q330,210 400,220 Q460,228 520,232 L570,234"
                      fill="none" stroke="#ec4899" stroke-width="3.5" stroke-linecap="round"
                      stroke-dasharray="600" stroke-dashoffset="600">
                    <animate attributeName="stroke-dashoffset" from="600" to="0" dur="4s" fill="freeze" repeatCount="indefinite"/>
                </path>

                <!-- Gradient fill under curve -->
                <path d="M60,50 Q120,60 150,100 Q200,160 260,190 Q330,210 400,220 Q460,228 520,232 L570,234 L570,240 L60,240 Z"
                      fill="url(#lossGrad)" opacity="0.25">
                    <animate attributeName="opacity" values="0;0.25" dur="4s" fill="freeze" repeatCount="indefinite"/>
                </path>
                <defs>
                    <linearGradient id="lossGrad" x1="0" y1="0" x2="0" y2="1">
                        <stop offset="0%" stop-color="#ec4899"/>
                        <stop offset="100%" stop-color="#fce7f3"/>
                    </linearGradient>
                </defs>

                <!-- Annotations -->
                <text x="85" y="45" fill="#ef4444" font-size="10" font-weight="700" font-family="Nunito">High loss (bad!)</text>
                <text x="450" y="218" fill="#22c55e" font-size="10" font-weight="700" font-family="Nunito">Low loss (good!)</text>

                <!-- Moving dot on curve -->
                <circle r="6" fill="#be185d">
                    <animateMotion dur="4s" repeatCount="indefinite"
                        path="M60,50 Q120,60 150,100 Q200,160 260,190 Q330,210 400,220 Q460,228 520,232 L570,234"/>
                </circle>
            </svg>
        </div>

        <div class="key-point">
            <h4>üí° Why Does the Loss Go Down?</h4>
            <ul>
                <li>Each iteration, backpropagation figures out which direction to nudge each weight to reduce the loss</li>
                <li><strong>Learning rate</strong> controls how big each nudge is ‚Äî too big and you overshoot, too small and training is painfully slow</li>
                <li>The curve is steep at first (lots to learn) then flattens out (fine-tuning details)</li>
                <li>If the loss stops decreasing, you might need: more data, a bigger model, or a different learning rate</li>
            </ul>
        </div>
    </div>

    <!-- ========== PART 5: Train a Simple Neural Net ========== -->
    <div class="section" id="code">
        <h2><i class="fas fa-code"></i> Part 5: Code ‚Äî Train a Simple Neural Net</h2>

        <p>Let's put everything together and build a neural network that predicts <strong>house prices</strong> from square footage. This is the simplest possible end-to-end example.</p>

        <div class="eli5">
            <h4>üë∂ What We're Building</h4>
            <p>We'll create fake house data (square footage ‚Üí price), build a tiny neural network (2 layers), train it for 500 epochs, and watch the loss go down. By the end, the network will have learned the relationship between house size and price ‚Äî <strong>without us ever telling it the formula</strong>.</p>
        </div>

        <h3>Step 1: Create the Dataset</h3>
        <div class="code-block">
            <span class="label">Python</span>
<pre><span class="keyword">import</span> torch
<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn

<span class="comment"># Fake data: price ‚âà 200 * sqft + noise</span>
torch.<span class="function">manual_seed</span>(<span class="number">42</span>)
sqft = torch.<span class="function">rand</span>(<span class="number">100</span>, <span class="number">1</span>) * <span class="number">5</span>         <span class="comment"># 0-5 (in thousands)</span>
price = <span class="number">200</span> * sqft + <span class="number">50</span> + torch.<span class="function">randn</span>(<span class="number">100</span>, <span class="number">1</span>) * <span class="number">20</span>

<span class="builtin">print</span>(<span class="string">f"sqft range: {sqft.min():.1f} - {sqft.max():.1f}"</span>)
<span class="builtin">print</span>(<span class="string">f"price range: {price.min():.0f} - {price.max():.0f}"</span>)</pre>
        </div>

        <h3>Step 2: Define the Model</h3>
        <div class="code-block">
            <span class="label">Python</span>
<pre><span class="keyword">class</span> <span class="function">HousePriceNet</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self):
        <span class="builtin">super</span>().<span class="function">__init__</span>()
        self.layers = nn.<span class="function">Sequential</span>(
            nn.<span class="function">Linear</span>(<span class="number">1</span>, <span class="number">16</span>),    <span class="comment"># 1 input (sqft) ‚Üí 16 hidden neurons</span>
            nn.<span class="function">ReLU</span>(),
            nn.<span class="function">Linear</span>(<span class="number">16</span>, <span class="number">1</span>),   <span class="comment"># 16 hidden ‚Üí 1 output (price)</span>
        )

    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        <span class="keyword">return</span> self.<span class="function">layers</span>(x)

model = <span class="function">HousePriceNet</span>()
<span class="builtin">print</span>(model)  <span class="comment"># Shows the architecture</span></pre>
        </div>

        <h3>Step 3: The Training Loop</h3>
        <div class="code-block">
            <span class="label">Python</span>
<pre>loss_fn = nn.<span class="function">MSELoss</span>()
optimizer = torch.optim.<span class="function">Adam</span>(model.<span class="function">parameters</span>(), lr=<span class="number">0.01</span>)

losses = []
<span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">500</span>):
    pred = <span class="function">model</span>(sqft)                <span class="comment"># ‚ë† Forward</span>
    loss = <span class="function">loss_fn</span>(pred, price)       <span class="comment"># ‚ë° Loss</span>
    loss.<span class="function">backward</span>()                   <span class="comment"># ‚ë¢ Backward</span>
    optimizer.<span class="function">step</span>()                  <span class="comment"># ‚ë£ Update</span>
    optimizer.<span class="function">zero_grad</span>()              <span class="comment"># ‚ë§ Zero grad</span>
    losses.<span class="function">append</span>(loss.<span class="function">item</span>())

    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:
        <span class="builtin">print</span>(<span class="string">f"Epoch {epoch:>3d} | Loss: {loss.item():.1f}"</span>)

<span class="comment"># Output:</span>
<span class="comment"># Epoch   0 | Loss: 132847.2</span>
<span class="comment"># Epoch 100 | Loss: 1205.3</span>
<span class="comment"># Epoch 200 | Loss: 418.7</span>
<span class="comment"># Epoch 300 | Loss: 394.2</span>
<span class="comment"># Epoch 400 | Loss: 389.8</span></pre>
        </div>

        <h3>Step 4: Make Predictions</h3>
        <div class="code-block">
            <span class="label">Python</span>
<pre><span class="comment"># Predict price for a 3,000 sqft house</span>
<span class="keyword">with</span> torch.<span class="function">no_grad</span>():
    test_sqft = torch.<span class="function">tensor</span>([[<span class="number">3.0</span>]])
    predicted = <span class="function">model</span>(test_sqft)
    <span class="builtin">print</span>(<span class="string">f"3,000 sqft ‚Üí predicted price: ${predicted.item():.0f}k"</span>)
    <span class="comment"># Expected: ~$650k  (200 * 3 + 50 = 650)</span></pre>
        </div>

        <!-- Interactive: Training Simulator -->
        <div class="playground" id="trainSim">
            <h4><i class="fas fa-play-circle"></i> Interactive: Watch Training in Action</h4>
            <p>Click "Train" to simulate 500 epochs. Watch the loss drop and the model's prediction line fit the data!</p>

            <div style="display:flex;gap:20px;flex-wrap:wrap;justify-content:center;margin-bottom:15px;">
                <button onclick="startTraining()" id="trainBtn"
                    style="background:linear-gradient(135deg,#ec4899,#db2777);color:white;border:none;padding:14px 36px;border-radius:14px;cursor:pointer;font-family:Nunito;font-weight:800;font-size:1.05em;box-shadow:0 4px 15px rgba(219,39,119,0.3);transition:all .3s;">
                    <i class="fas fa-play"></i> Train!
                </button>
                <button onclick="resetTraining()" id="resetBtn"
                    style="background:rgba(255,255,255,0.7);color:#475569;border:1px solid #e2e8f0;padding:14px 36px;border-radius:14px;cursor:pointer;font-family:Nunito;font-weight:700;font-size:1.05em;">
                    <i class="fas fa-redo"></i> Reset
                </button>
            </div>

            <div style="display:flex;gap:15px;justify-content:center;flex-wrap:wrap;margin-bottom:12px;">
                <div style="background:white;border-radius:12px;padding:12px 20px;border:1px solid #fbcfe8;min-width:150px;">
                    <div style="font-size:0.8em;color:#6b7280;">Epoch</div>
                    <div style="font-size:1.5em;font-weight:900;color:#be185d;" id="simEpoch">0</div>
                </div>
                <div style="background:white;border-radius:12px;padding:12px 20px;border:1px solid #fbcfe8;min-width:150px;">
                    <div style="font-size:0.8em;color:#6b7280;">Loss</div>
                    <div style="font-size:1.5em;font-weight:900;color:#ef4444;" id="simLoss">‚Äî</div>
                </div>
            </div>

            <svg viewBox="0 0 500 250" id="trainChart" xmlns="http://www.w3.org/2000/svg" style="background:white;border-radius:14px;border:1px solid #fbcfe8;">
                <rect width="500" height="250" rx="14" fill="white"/>
                <!-- Data points -->
                <g id="dataPoints"></g>
                <!-- Prediction line -->
                <line id="predLine" x1="40" y1="220" x2="460" y2="220" stroke="#ec4899" stroke-width="3" stroke-dasharray="0" opacity="0"/>
                <!-- Axes -->
                <line x1="40" y1="220" x2="460" y2="220" stroke="#cbd5e1" stroke-width="1.5"/>
                <line x1="40" y1="20" x2="40" y2="220" stroke="#cbd5e1" stroke-width="1.5"/>
                <text x="250" y="245" text-anchor="middle" fill="#6b7280" font-size="10" font-family="Nunito">Square Footage (thousands)</text>
                <text x="15" y="120" text-anchor="middle" fill="#6b7280" font-size="10" font-family="Nunito" transform="rotate(-90,15,120)">Price ($k)</text>
            </svg>
        </div>

        <div class="key-point">
            <h4>üéì What You Just Learned</h4>
            <ul>
                <li>How to create a dataset with PyTorch tensors</li>
                <li>How to define a model using <code>nn.Module</code> and <code>nn.Sequential</code></li>
                <li>The 5-step training loop: forward ‚Üí loss ‚Üí backward ‚Üí step ‚Üí zero_grad</li>
                <li>How to make predictions with <code>torch.no_grad()</code></li>
                <li>This exact pattern scales from 2 layers to GPT-4's 96 layers ‚Äî only the model definition changes!</li>
            </ul>
        </div>

        <div class="eli5">
            <h4>üîó How This Connects to LLMs</h4>
            <p>LLMs like GPT are just <strong>much bigger</strong> neural networks. Instead of predicting house prices from square footage, they predict the next word from all the previous words. Instead of 2 layers, they have 96+. Instead of 16 neurons per layer, they have 12,288. But the training loop? <strong>Exactly the same 5 steps.</strong> That's the beauty of deep learning ‚Äî the core idea scales from a toy to the most powerful AI on Earth.</p>
        </div>
    </div>

    <div class="nav-buttons">
        <a href="text-to-numbers.html" class="nav-btn prev"><i class="fas fa-arrow-left"></i> Prev: Text to Numbers</a>
        <a href="attention.html" class="nav-btn next">Next: Attention <i class="fas fa-arrow-right"></i></a>
    </div>
</div>

<script>
// ========== Neuron Playground ==========
function updateNeuron() {
    var x = parseFloat(document.getElementById('sliderX').value);
    var w = parseFloat(document.getElementById('sliderW').value);
    var b = parseFloat(document.getElementById('sliderB').value);
    document.getElementById('valX').textContent = x.toFixed(1);
    document.getElementById('valW').textContent = w.toFixed(1);
    document.getElementById('valB').textContent = b.toFixed(1);
    var z = x * w + b;
    var relu = Math.max(0, z);
    document.getElementById('calcZ').textContent = z.toFixed(2);
    document.getElementById('calcRelu').textContent = relu.toFixed(2);
    var pct = Math.min(100, Math.max(0, (relu / 10) * 100));
    document.getElementById('reluBar').style.width = pct + '%';
    document.getElementById('reluBarLabel').textContent = relu.toFixed(2);
}
updateNeuron();

// ========== Training Simulator ==========
var simData = [];
var simRunning = false;
var simFrame = null;

function initData() {
    simData = [];
    for (var i = 0; i < 40; i++) {
        var sq = Math.random() * 4.2 + 0.4;
        var pr = 200 * sq + 50 + (Math.random() - 0.5) * 80;
        simData.push({ x: sq, y: pr });
    }
    var g = document.getElementById('dataPoints');
    g.innerHTML = '';
    var svg = document.getElementById('trainChart');
    for (var i = 0; i < simData.length; i++) {
        var cx = 40 + (simData[i].x / 5) * 420;
        var cy = 220 - ((simData[i].y - 0) / 1200) * 200;
        var c = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
        c.setAttribute('cx', cx);
        c.setAttribute('cy', Math.max(20, Math.min(220, cy)));
        c.setAttribute('r', '4');
        c.setAttribute('fill', '#f9a8d4');
        c.setAttribute('stroke', '#ec4899');
        c.setAttribute('stroke-width', '1.5');
        g.appendChild(c);
    }
}

function startTraining() {
    if (simRunning) return;
    simRunning = true;
    document.getElementById('trainBtn').style.opacity = '0.6';

    var w = Math.random() * 50;
    var bParam = Math.random() * 100;
    var lr = 0.0002;
    var epoch = 0;
    var maxEpoch = 500;

    function step() {
        if (epoch >= maxEpoch) {
            simRunning = false;
            document.getElementById('trainBtn').style.opacity = '1';
            return;
        }

        var totalLoss = 0;
        var dw = 0, db = 0;
        for (var i = 0; i < simData.length; i++) {
            var pred = w * simData[i].x + bParam;
            var err = pred - simData[i].y;
            totalLoss += err * err;
            dw += 2 * err * simData[i].x;
            db += 2 * err;
        }
        totalLoss /= simData.length;
        dw /= simData.length;
        db /= simData.length;

        w -= lr * dw;
        bParam -= lr * db;
        epoch++;

        if (epoch % 5 === 0 || epoch === 1) {
            document.getElementById('simEpoch').textContent = epoch;
            document.getElementById('simLoss').textContent = totalLoss.toFixed(0);

            var line = document.getElementById('predLine');
            var y0 = 220 - ((w * 0 + bParam) / 1200) * 200;
            var y5 = 220 - ((w * 5 + bParam) / 1200) * 200;
            line.setAttribute('x1', 40);
            line.setAttribute('y1', Math.max(20, Math.min(220, y0)));
            line.setAttribute('x2', 460);
            line.setAttribute('y2', Math.max(20, Math.min(220, y5)));
            line.setAttribute('opacity', '1');
        }

        simFrame = requestAnimationFrame(step);
    }
    step();
}

function resetTraining() {
    simRunning = false;
    if (simFrame) cancelAnimationFrame(simFrame);
    document.getElementById('trainBtn').style.opacity = '1';
    document.getElementById('simEpoch').textContent = '0';
    document.getElementById('simLoss').textContent = '‚Äî';
    document.getElementById('predLine').setAttribute('opacity', '0');
    initData();
}

initData();
</script>
</body>
</html>
